{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a9912f3cbf0467ca5d0e4360cce8ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c69dabe6825453586c59b058fc389dd",
              "IPY_MODEL_36f6113aea0c4aa5ad0b9e6ef5df54ee",
              "IPY_MODEL_7ac3e32ffe84417b972c43e77bb855aa"
            ],
            "layout": "IPY_MODEL_e43af5fe1dd84abca8568402a1b6a1c5"
          }
        },
        "3c69dabe6825453586c59b058fc389dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1688aef75357464ab808d68db66d93dd",
            "placeholder": "​",
            "style": "IPY_MODEL_19175b5ce54948d7a169a51e5598a1c7",
            "value": "100%"
          }
        },
        "36f6113aea0c4aa5ad0b9e6ef5df54ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a303de07ac54a75b6899993c451609c",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94f665510f934dff8b03dd53c0cf98e7",
            "value": 111898327
          }
        },
        "7ac3e32ffe84417b972c43e77bb855aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09d4d1d46e984d43938872406685a954",
            "placeholder": "​",
            "style": "IPY_MODEL_a50ae2b971c14919984170ea9404e351",
            "value": " 107M/107M [00:00&lt;00:00, 121MB/s]"
          }
        },
        "e43af5fe1dd84abca8568402a1b6a1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1688aef75357464ab808d68db66d93dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19175b5ce54948d7a169a51e5598a1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a303de07ac54a75b6899993c451609c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f665510f934dff8b03dd53c0cf98e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09d4d1d46e984d43938872406685a954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50ae2b971c14919984170ea9404e351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZoFj5mgjt15R"
      },
      "outputs": [],
      "source": [
        "#Rag audio and video project\n",
        "!pip install -q -U google-generativeai\n",
        "# # This command installs the google-generativeai library.\n",
        "# -q: Suppresses unnecessary output during the installation.\n",
        "# -U: Ensures the latest version of the library is installed (it upgrades the package if an older version is already installed)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simply taking the api key,\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "l20zfFKEyU6z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())\n",
        "# gives the complete list of all the google models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kzXcSSLsyqRr",
        "outputId": "1c1db137-857f-408d-f9cf-1ee5046309ec",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Latest',\n",
              "       description=('The original Gemini 1.0 Pro model. This model will be discontinued on '\n",
              "                    'February 15th, 2025. Move to a newer Gemini version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "       description=('The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 '\n",
              "                    'Pro will be discontinued on February 15th, 2025. Move to a newer Gemini '\n",
              "                    'version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-exp-0801',\n",
              "       base_model_id='',\n",
              "       version='exp-0801',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='exp_1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1121',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1114',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in here we are selecting a model for our textual embedding, by giving it out some texts, then we tell it that\n",
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=[\n",
        "        \"What is the meaning of life?\",\n",
        "        \"How much wood would a woodchuck chuck?\",\n",
        "        \"How does the brain work?\",\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",  #task_type=\"retrieval_document\": Indicates the type of task. Here, embeddings are being generated for document retrieval.In this case, the task_type=\"retrieval_document\" ensures that the embeddings are optimized for document retrieval tasks rather than other possible tasks, such as:\n",
        "# Classification: Optimized for labeling categories (e.g., spam detection).\n",
        "# Clustering: Optimized for grouping similar items.\n",
        "# Search or Ranking: Optimized for matching queries with results.\n",
        "# By explicitly specifying retrieval_document, the model fine-tunes the embeddings to capture relationships that are most useful for finding and retrieving relevant documents.\n",
        "    title=\"Embedding of list of strings\", #The title parameter is metadata—additional information describing the embedding task.\n",
        ")\n",
        "\n",
        "# A list of inputs > A list of vectors output\n",
        "for v in result[\"embedding\"]:\n",
        "    print(str(v)[:50], \"... TRIMMED ...\", len(v))"
      ],
      "metadata": {
        "id": "kvNuXmJHzaMb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e4fca0ab-7b0b-49b4-e6a4-ef7b3cf6dab2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.036453027, 0.033254996, -0.03970925, -0.002628 ... TRIMMED ... 768\n",
            "[-0.01591948, 0.032582663, -0.081024624, -0.011298 ... TRIMMED ... 768\n",
            "[0.00037063024, 0.03763057, -0.122695684, -0.00951 ... TRIMMED ... 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#First Part: (ABOVE)\n",
        "\n",
        "Embedding Generation: Uses Google Generative AI API to generate text embeddings (vectors).\n",
        "\n",
        "#Second Part: ##(BELOW)\n",
        "\n",
        "Vector Database: Embeddings are stored in Chroma DB, a vector database designed for efficient storage and retrieval of embeddings."
      ],
      "metadata": {
        "id": "tVxFGv9zJIVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-chroma\n",
        "# database that lcoally install the vectors, we can use pinecone also but its online and is cloud based, this isntall the cectors at your lcoal machinne"
      ],
      "metadata": {
        "id": "WGNDO_IO3nv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7284e9-4049-43f2-d67d-f48450fb4f9d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass #  getpass Module:\n",
        "# Purpose: This module is used to securely handle and prompt the user for sensitive information, like passwords, without showing the input in the console or terminal.\n",
        "# Common Use: It's typically used when you need to collect passwords, API keys, or other sensitive data in a secure way (i.e., without displaying the typed characters)\n",
        "import os"
      ],
      "metadata": {
        "id": "RG2JDT3c7u7K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
        "        metadata={\"source\": \"fish-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
        "        metadata={\"source\": \"bird-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "tD6tDBY0-d9S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-google-genai\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings # langchain-google-genai: This is a wrapper for LangChain that integrates the Google Generative AI API into LangChain’s framework.\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\",\n",
        "                                          google_api_key=userdata.get('GOOGLE_API_KEY')) #LangChain might not automatically inherit the API key: The LangChain wrapper (the GoogleGenerativeAIEmbeddings\n"
      ],
      "metadata": {
        "id": "ISNTNnkvIVh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e370a6a9-6698-43b2-bd86-25c698ed16dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.embed_query(\"What's our Q1 revenue?\") #this is making the embedding for the words i have written under"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "za049jsJI-cr",
        "outputId": "173444e2-46e4-41f4-bd72-1ecaa46a5850"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.040674030780792236,\n",
              " 0.006255019456148148,\n",
              " -0.013568978756666183,\n",
              " -0.0003686861018650234,\n",
              " 0.04303165152668953,\n",
              " 0.04935013875365257,\n",
              " -0.013514830730855465,\n",
              " -0.027903610840439796,\n",
              " -0.03995805233716965,\n",
              " -0.006844368763267994,\n",
              " 0.0013024156214669347,\n",
              " -0.009539234451949596,\n",
              " 0.0705987736582756,\n",
              " -0.009862210601568222,\n",
              " 0.03167127072811127,\n",
              " -0.02663198858499527,\n",
              " -0.018167555332183838,\n",
              " -0.005245935637503862,\n",
              " -0.14866198599338531,\n",
              " -0.01596848852932453,\n",
              " 0.02811194583773613,\n",
              " -0.0018506837077438831,\n",
              " -0.025303209200501442,\n",
              " -0.01434125192463398,\n",
              " -0.03104301728308201,\n",
              " -0.07088255137205124,\n",
              " 0.011673162691295147,\n",
              " 0.008746510371565819,\n",
              " 0.003015926806256175,\n",
              " -0.010475549846887589,\n",
              " -6.184780795592815e-05,\n",
              " -0.0014338439796119928,\n",
              " -0.03641575202345848,\n",
              " -0.0519932359457016,\n",
              " -0.02123081497848034,\n",
              " 0.03613690286874771,\n",
              " -0.03694721683859825,\n",
              " 0.06530386954545975,\n",
              " 0.031148776412010193,\n",
              " -0.05865824222564697,\n",
              " -0.033094197511672974,\n",
              " -0.002400598954409361,\n",
              " -0.039360735565423965,\n",
              " 0.001522441511042416,\n",
              " 0.03487030044198036,\n",
              " 0.0026657148264348507,\n",
              " -0.0058933584950864315,\n",
              " 0.020132659003138542,\n",
              " -0.0036536972038447857,\n",
              " 0.008130554109811783,\n",
              " -0.009108034893870354,\n",
              " -0.03555028885602951,\n",
              " -0.014387637376785278,\n",
              " 0.0020767864771187305,\n",
              " -0.047531772404909134,\n",
              " -0.023021064698696136,\n",
              " 0.02736302837729454,\n",
              " -0.026102488860487938,\n",
              " 0.08498480916023254,\n",
              " -0.009469239041209221,\n",
              " 0.0319310761988163,\n",
              " -0.0018667412223294377,\n",
              " 0.059389110654592514,\n",
              " -0.0035042506642639637,\n",
              " 0.020587773993611336,\n",
              " -0.03917128965258598,\n",
              " 0.03360649570822716,\n",
              " 0.015973566100001335,\n",
              " -0.0738484337925911,\n",
              " -0.02538050338625908,\n",
              " -0.02277788706123829,\n",
              " 0.05237537994980812,\n",
              " 0.011328230611979961,\n",
              " -0.03981751948595047,\n",
              " -0.0006608059629797935,\n",
              " -0.008069388568401337,\n",
              " 0.007512678857892752,\n",
              " -0.04804745689034462,\n",
              " 0.03459799289703369,\n",
              " 0.08978776633739471,\n",
              " -0.07167279720306396,\n",
              " 0.022603409364819527,\n",
              " 0.08019706606864929,\n",
              " 0.00940668024122715,\n",
              " 0.03418527916073799,\n",
              " -0.015340480022132397,\n",
              " -0.03552362322807312,\n",
              " -0.03181988373398781,\n",
              " -0.05383983999490738,\n",
              " -0.04403817653656006,\n",
              " 0.05618930980563164,\n",
              " -0.02780766971409321,\n",
              " -0.02107255905866623,\n",
              " -0.018637580797076225,\n",
              " 0.0897323489189148,\n",
              " -0.06604108214378357,\n",
              " -0.09660559147596359,\n",
              " -0.05220397189259529,\n",
              " 0.07147490233182907,\n",
              " 0.06639932841062546,\n",
              " 0.004779261536896229,\n",
              " -0.03112303651869297,\n",
              " 0.0008881306857801974,\n",
              " 0.01845836080610752,\n",
              " 0.0274297297000885,\n",
              " 0.0004622933629434556,\n",
              " -0.03492116928100586,\n",
              " -0.004169788211584091,\n",
              " -0.021554481238126755,\n",
              " -0.02542758919298649,\n",
              " -0.02286696434020996,\n",
              " -0.03512721508741379,\n",
              " 0.0026910000015050173,\n",
              " -0.028166597709059715,\n",
              " 0.004026286769658327,\n",
              " -0.00791264045983553,\n",
              " -0.024778082966804504,\n",
              " 0.015024474821984768,\n",
              " -0.010839731432497501,\n",
              " 0.009473622776567936,\n",
              " 0.056382134556770325,\n",
              " 0.021171119064092636,\n",
              " -0.008079694584012032,\n",
              " 0.025672005489468575,\n",
              " 0.028384380042552948,\n",
              " 0.020231332629919052,\n",
              " 0.0428866408765316,\n",
              " -0.0007346387719735503,\n",
              " -0.03555949404835701,\n",
              " -0.05524420365691185,\n",
              " -0.014625327661633492,\n",
              " 0.009426695294678211,\n",
              " 0.010897071100771427,\n",
              " -0.003945027478039265,\n",
              " 0.022394057363271713,\n",
              " -0.024528535082936287,\n",
              " 0.0876956656575203,\n",
              " 0.04642253741621971,\n",
              " -0.030577486380934715,\n",
              " 0.03828105702996254,\n",
              " 0.03191431239247322,\n",
              " -0.04186468943953514,\n",
              " -0.06275169551372528,\n",
              " 0.014168639667332172,\n",
              " -0.01498769223690033,\n",
              " -0.024832768365740776,\n",
              " 0.027766933664679527,\n",
              " -0.0004999113152734935,\n",
              " -0.025478815659880638,\n",
              " -0.03067292645573616,\n",
              " -0.027004195377230644,\n",
              " 0.005373257678002119,\n",
              " -0.005426143296062946,\n",
              " -0.013760142959654331,\n",
              " 0.047259990125894547,\n",
              " -3.351004352225573e-06,\n",
              " 0.011196448467671871,\n",
              " 0.0331735797226429,\n",
              " 0.04530906677246094,\n",
              " 0.026219498366117477,\n",
              " -0.03507794439792633,\n",
              " 0.013839093036949635,\n",
              " -0.02348119020462036,\n",
              " 0.028220539912581444,\n",
              " -0.039287421852350235,\n",
              " 0.023950839415192604,\n",
              " -0.02938219904899597,\n",
              " -0.003724222769960761,\n",
              " 0.03192543610930443,\n",
              " 0.0069425287656486034,\n",
              " -0.02548467367887497,\n",
              " -0.03700289875268936,\n",
              " -0.053304944187402725,\n",
              " -0.06592298299074173,\n",
              " -0.01140379998832941,\n",
              " 0.07297323644161224,\n",
              " -0.010483955964446068,\n",
              " -0.04604703560471535,\n",
              " -0.12386089563369751,\n",
              " -0.05467037111520767,\n",
              " 0.03335092216730118,\n",
              " 0.013243228197097778,\n",
              " -0.05039249360561371,\n",
              " -0.008832715451717377,\n",
              " 0.06478633731603622,\n",
              " 0.04017411917448044,\n",
              " 0.0036366560962051153,\n",
              " -0.026531219482421875,\n",
              " -0.015908753499388695,\n",
              " 0.006120656616985798,\n",
              " -0.01062320638448,\n",
              " 0.005162350367754698,\n",
              " 0.032537247985601425,\n",
              " -0.042312879115343094,\n",
              " 0.017654040828347206,\n",
              " 0.05063820630311966,\n",
              " 0.042538005858659744,\n",
              " -0.03213687241077423,\n",
              " -0.038917768746614456,\n",
              " 0.010565686970949173,\n",
              " -0.010164313018321991,\n",
              " -0.029124340042471886,\n",
              " 0.028939809650182724,\n",
              " -0.046825725585222244,\n",
              " -0.04041363671422005,\n",
              " -0.02851947396993637,\n",
              " -0.05352668836712837,\n",
              " -0.023540807887911797,\n",
              " -0.05905939266085625,\n",
              " 0.006182074546813965,\n",
              " 0.0236660148948431,\n",
              " 0.01643635518848896,\n",
              " -0.055969204753637314,\n",
              " -0.052113115787506104,\n",
              " 0.005142379552125931,\n",
              " 0.015834525227546692,\n",
              " 0.07765226811170578,\n",
              " 0.014419138431549072,\n",
              " 0.014757545664906502,\n",
              " -0.016682716086506844,\n",
              " 0.035169124603271484,\n",
              " -0.012445286847651005,\n",
              " 0.04094401374459267,\n",
              " -0.0004567909345496446,\n",
              " 0.03075295127928257,\n",
              " 0.015191249549388885,\n",
              " 0.0008787462138570845,\n",
              " 0.011183375492691994,\n",
              " -0.02541988343000412,\n",
              " -0.01335611566901207,\n",
              " 0.04078405350446701,\n",
              " 0.00097758905030787,\n",
              " -0.027971843257546425,\n",
              " 0.03310989588499069,\n",
              " -0.036995869129896164,\n",
              " 0.07041022926568985,\n",
              " 0.038847681134939194,\n",
              " 0.011135242879390717,\n",
              " 0.0178934745490551,\n",
              " -0.06709057837724686,\n",
              " -0.018150683492422104,\n",
              " -0.004681224934756756,\n",
              " -0.020785439759492874,\n",
              " -0.0015118676237761974,\n",
              " -0.01593458652496338,\n",
              " 0.008007141761481762,\n",
              " 0.056374192237854004,\n",
              " 0.018349969759583473,\n",
              " -0.01836358942091465,\n",
              " -0.03326503559947014,\n",
              " -0.062389075756073,\n",
              " 0.012848050333559513,\n",
              " -0.0030290777795016766,\n",
              " 0.00806711707264185,\n",
              " -0.06129119545221329,\n",
              " -0.009198661893606186,\n",
              " 0.0034411519300192595,\n",
              " -0.05829843878746033,\n",
              " 0.017203867435455322,\n",
              " 0.07828714698553085,\n",
              " 0.02788754366338253,\n",
              " -0.05472508445382118,\n",
              " -0.0053860764019191265,\n",
              " -0.04209680110216141,\n",
              " -0.057854652404785156,\n",
              " -0.06215570494532585,\n",
              " -0.037162765860557556,\n",
              " -0.026187805458903313,\n",
              " 0.013729006983339787,\n",
              " 0.00522513035684824,\n",
              " 0.007254887372255325,\n",
              " 0.007314743008464575,\n",
              " -0.044295214116573334,\n",
              " 0.012690248899161816,\n",
              " 0.0015951964305713773,\n",
              " -0.020993180572986603,\n",
              " -0.028973281383514404,\n",
              " 0.01797867938876152,\n",
              " -0.03705243021249771,\n",
              " 0.016344338655471802,\n",
              " 0.047140851616859436,\n",
              " -0.0045312875881791115,\n",
              " 0.020043889060616493,\n",
              " -0.04180380329489708,\n",
              " 0.008862539194524288,\n",
              " 0.011784982867538929,\n",
              " 0.012936141341924667,\n",
              " 0.04847110062837601,\n",
              " 0.020518505945801735,\n",
              " -0.04009382799267769,\n",
              " 0.004235445521771908,\n",
              " -0.015121255069971085,\n",
              " -0.017107676714658737,\n",
              " -0.0022628495935350657,\n",
              " 0.03131377324461937,\n",
              " 0.058326173573732376,\n",
              " 0.047612544149160385,\n",
              " 0.0008990900823846459,\n",
              " 0.012505724094808102,\n",
              " 0.0234519150108099,\n",
              " 0.011617792770266533,\n",
              " 0.0089767687022686,\n",
              " 0.012201692909002304,\n",
              " 0.05818939581513405,\n",
              " 0.07964139431715012,\n",
              " 0.02628134936094284,\n",
              " 0.0035562783014029264,\n",
              " -0.06586579233407974,\n",
              " -0.06682974845170975,\n",
              " -0.004343168810009956,\n",
              " 0.024766702204942703,\n",
              " -0.045907892286777496,\n",
              " -0.024228105321526527,\n",
              " -0.04364803433418274,\n",
              " -0.01721922867000103,\n",
              " -0.014083858579397202,\n",
              " -0.08534359931945801,\n",
              " -0.022292688488960266,\n",
              " -0.035723213106393814,\n",
              " -0.05347568914294243,\n",
              " 0.04860648512840271,\n",
              " -0.024981264024972916,\n",
              " -0.05546209588646889,\n",
              " -0.02599288523197174,\n",
              " 0.059800885617733,\n",
              " 0.027545634657144547,\n",
              " 0.010634008795022964,\n",
              " 0.030378857627511024,\n",
              " -0.06266247481107712,\n",
              " -0.02802923507988453,\n",
              " -0.0164673812687397,\n",
              " -0.00466604670509696,\n",
              " 0.0068775867111980915,\n",
              " -0.04135647043585777,\n",
              " 0.013757770881056786,\n",
              " 0.030090903863310814,\n",
              " -0.051660291850566864,\n",
              " 0.035671450197696686,\n",
              " 0.05833543464541435,\n",
              " 0.030305322259664536,\n",
              " 0.030703585594892502,\n",
              " 0.045433782041072845,\n",
              " 0.035327911376953125,\n",
              " 0.04064740985631943,\n",
              " -0.02929910458624363,\n",
              " 0.0028224694542586803,\n",
              " 0.04217402637004852,\n",
              " 0.017522307112812996,\n",
              " -0.02317088656127453,\n",
              " -0.012836667709052563,\n",
              " 0.016060883179306984,\n",
              " 0.07096286863088608,\n",
              " 0.022300882264971733,\n",
              " -0.030652055516839027,\n",
              " -0.02046220190823078,\n",
              " -0.008860406465828419,\n",
              " 0.044191617518663406,\n",
              " 0.012760547921061516,\n",
              " 0.017109554260969162,\n",
              " 0.00567222386598587,\n",
              " 0.020018693059682846,\n",
              " -0.015990694984793663,\n",
              " -0.03650399297475815,\n",
              " -0.010141105391085148,\n",
              " -0.024074191227555275,\n",
              " 0.03260262683033943,\n",
              " 0.01904658041894436,\n",
              " 0.03513059765100479,\n",
              " -0.012212435714900494,\n",
              " 0.0036663140635937452,\n",
              " -0.0070173488929867744,\n",
              " -0.03424908220767975,\n",
              " 0.036729518324136734,\n",
              " 0.01946347951889038,\n",
              " -0.00860413908958435,\n",
              " -0.04971911385655403,\n",
              " -0.059182457625865936,\n",
              " -0.002848780946806073,\n",
              " 0.031969111412763596,\n",
              " -0.026185661554336548,\n",
              " 0.05550776794552803,\n",
              " -0.004006619565188885,\n",
              " -0.051209691911935806,\n",
              " 0.06815080344676971,\n",
              " -0.05306592956185341,\n",
              " 0.020680462941527367,\n",
              " -0.07201379537582397,\n",
              " -0.01924624852836132,\n",
              " 0.005424595437943935,\n",
              " -0.043159838765859604,\n",
              " -0.004355010110884905,\n",
              " -0.0022963096853345633,\n",
              " 0.028794437646865845,\n",
              " 0.030889587476849556,\n",
              " -0.007004606071859598,\n",
              " 0.07111821323633194,\n",
              " -0.013412009924650192,\n",
              " -0.014901253394782543,\n",
              " 0.014481945894658566,\n",
              " -0.038996364921331406,\n",
              " -0.03584769740700722,\n",
              " -0.0066221775487065315,\n",
              " 0.008168015629053116,\n",
              " -0.03866076096892357,\n",
              " -0.024964667856693268,\n",
              " -0.03399388864636421,\n",
              " 0.07047809660434723,\n",
              " -0.002807113341987133,\n",
              " -0.0026940142270177603,\n",
              " -0.02858911268413067,\n",
              " 0.06441131234169006,\n",
              " 0.022924337536096573,\n",
              " -0.038946185261011124,\n",
              " -0.005655820947140455,\n",
              " -0.05000632628798485,\n",
              " -0.014447260648012161,\n",
              " -0.002026891801506281,\n",
              " 0.0030106124468147755,\n",
              " 0.05433937534689903,\n",
              " 0.0038927753921598196,\n",
              " 0.01058945618569851,\n",
              " -0.020083194598555565,\n",
              " 0.06434295326471329,\n",
              " -0.037731949239969254,\n",
              " 0.019364971667528152,\n",
              " -0.01708812639117241,\n",
              " -0.007275398354977369,\n",
              " 0.006923719309270382,\n",
              " 0.03294694796204567,\n",
              " 0.008821401745080948,\n",
              " -0.035904500633478165,\n",
              " 0.023028215393424034,\n",
              " -0.028629709035158157,\n",
              " -0.012202284298837185,\n",
              " -0.07996783405542374,\n",
              " 0.009951084852218628,\n",
              " -0.018842991441488266,\n",
              " 0.04279767721891403,\n",
              " 0.0063218362629413605,\n",
              " -0.020923594012856483,\n",
              " 0.01167957205325365,\n",
              " 0.02149077132344246,\n",
              " 0.04855334386229515,\n",
              " 0.01931636407971382,\n",
              " -0.00798702146857977,\n",
              " 0.005307495128363371,\n",
              " -0.010870776139199734,\n",
              " 0.02465776912868023,\n",
              " -0.05784374848008156,\n",
              " -0.012009432539343834,\n",
              " -0.0010353594552725554,\n",
              " 0.001357968314550817,\n",
              " 0.03233030438423157,\n",
              " -0.03482642024755478,\n",
              " -0.04115253686904907,\n",
              " -0.0016379851149395108,\n",
              " -0.016736943274736404,\n",
              " 0.03030269965529442,\n",
              " 0.0070823547430336475,\n",
              " 0.013011662289500237,\n",
              " 0.0013094530440866947,\n",
              " -0.023420250043272972,\n",
              " 0.04642616957426071,\n",
              " 0.04938816651701927,\n",
              " 0.011798360385000706,\n",
              " -0.045309584587812424,\n",
              " 0.009469387121498585,\n",
              " -0.005720063112676144,\n",
              " -0.005492646712809801,\n",
              " 0.07672107964754105,\n",
              " 0.05767561495304108,\n",
              " -0.016651729121804237,\n",
              " 0.01272104773670435,\n",
              " -0.028916891664266586,\n",
              " -0.01569833792746067,\n",
              " 0.013438977301120758,\n",
              " -0.04521883279085159,\n",
              " -0.04580063745379448,\n",
              " -0.06875801086425781,\n",
              " -0.008748088032007217,\n",
              " 0.0034978643525391817,\n",
              " -0.05619722977280617,\n",
              " -0.046840690076351166,\n",
              " 0.049902353435754776,\n",
              " 0.03386502340435982,\n",
              " -0.008411991409957409,\n",
              " -0.003451331052929163,\n",
              " -0.02074151486158371,\n",
              " 0.07574094086885452,\n",
              " -0.01795017346739769,\n",
              " 0.015205703675746918,\n",
              " 0.020769039168953896,\n",
              " -0.0004893033183179796,\n",
              " -0.04977618157863617,\n",
              " -0.06083740293979645,\n",
              " -0.011869067326188087,\n",
              " 0.04016096889972687,\n",
              " -0.0056722043082118034,\n",
              " -0.02773195691406727,\n",
              " 0.01636294275522232,\n",
              " 0.01701270416378975,\n",
              " 0.03908716142177582,\n",
              " -0.015088760294020176,\n",
              " -0.03776533156633377,\n",
              " -0.02017400600016117,\n",
              " -0.05718950182199478,\n",
              " -0.04964404180645943,\n",
              " -0.008687540888786316,\n",
              " -0.00674031674861908,\n",
              " -0.009721371345221996,\n",
              " 0.00877001229673624,\n",
              " -0.04894879087805748,\n",
              " 0.029544781893491745,\n",
              " 0.0656760111451149,\n",
              " 0.01786809228360653,\n",
              " 0.03679507598280907,\n",
              " -0.048695698380470276,\n",
              " 0.05084334313869476,\n",
              " -0.0012932618847116828,\n",
              " -0.014733269810676575,\n",
              " -0.0942688137292862,\n",
              " -0.005923083983361721,\n",
              " 0.0548890121281147,\n",
              " -0.0027005928568542004,\n",
              " 0.026992907747626305,\n",
              " -0.00731872720643878,\n",
              " -0.06826119124889374,\n",
              " -0.02900216169655323,\n",
              " 0.004012713208794594,\n",
              " 0.013650557026267052,\n",
              " 0.02704375982284546,\n",
              " 0.03710830584168434,\n",
              " 0.033099979162216187,\n",
              " 0.01301198173314333,\n",
              " -0.05733863264322281,\n",
              " 0.025459110736846924,\n",
              " 0.024094557389616966,\n",
              " -0.007090229541063309,\n",
              " -0.025551943108439445,\n",
              " 0.036184437572956085,\n",
              " 0.038272250443696976,\n",
              " -0.027310671284794807,\n",
              " 0.027453413233160973,\n",
              " 0.038615234196186066,\n",
              " 0.02579406090080738,\n",
              " 0.05250363424420357,\n",
              " 0.022117899730801582,\n",
              " -0.05710281804203987,\n",
              " -0.0017957596573978662,\n",
              " 0.03591448813676834,\n",
              " -0.005846180021762848,\n",
              " -0.06997204571962357,\n",
              " 0.00024452630896121264,\n",
              " -0.010681462474167347,\n",
              " 0.06773526221513748,\n",
              " -0.005376582033932209,\n",
              " 0.022301286458969116,\n",
              " 0.022317348048090935,\n",
              " 0.012877714820206165,\n",
              " -0.04674927517771721,\n",
              " 0.05696335807442665,\n",
              " -0.01296178437769413,\n",
              " 0.016913650557398796,\n",
              " -0.053046829998493195,\n",
              " -0.002701016841456294,\n",
              " 0.003923126962035894,\n",
              " 0.03747446462512016,\n",
              " 0.11272288858890533,\n",
              " -0.0015829706098884344,\n",
              " -0.05584847927093506,\n",
              " 0.09707442671060562,\n",
              " -0.00024738904903642833,\n",
              " -0.03714948520064354,\n",
              " -0.04195793718099594,\n",
              " 0.009514124132692814,\n",
              " 0.019299393519759178,\n",
              " -0.03335732966661453,\n",
              " 0.0021547258365899324,\n",
              " 0.053686920553445816,\n",
              " -0.03058801032602787,\n",
              " -0.0028617610223591328,\n",
              " 0.03269273787736893,\n",
              " 0.02336142770946026,\n",
              " -0.018097469583153725,\n",
              " -0.020934492349624634,\n",
              " 0.03093210980296135,\n",
              " -0.008286625146865845,\n",
              " -0.029237965121865273,\n",
              " -0.03758196532726288,\n",
              " -0.02840360254049301,\n",
              " 0.053243815898895264,\n",
              " 0.010723110288381577,\n",
              " -0.020957577973604202,\n",
              " -0.022098371759057045,\n",
              " 0.06305725127458572,\n",
              " -0.023262832313776016,\n",
              " 0.01595097780227661,\n",
              " 0.00835984107106924,\n",
              " 0.07245082408189774,\n",
              " 0.008686445653438568,\n",
              " 0.0012503870530053973,\n",
              " 7.557651406386867e-05,\n",
              " 0.03862207755446434,\n",
              " -0.019229695200920105,\n",
              " 0.014497706666588783,\n",
              " 0.012569671496748924,\n",
              " -0.026799125596880913,\n",
              " 0.019178958609700203,\n",
              " 0.026653669774532318,\n",
              " -0.014713150449097157,\n",
              " -0.00043338595423847437,\n",
              " 0.08456723392009735,\n",
              " -0.062270551919937134,\n",
              " 0.008901653811335564,\n",
              " -0.0008224630146287382,\n",
              " -0.009016134776175022,\n",
              " 0.010196023620665073,\n",
              " -0.05758286267518997,\n",
              " 0.001213831827044487,\n",
              " -0.012950764037668705,\n",
              " 0.08539506793022156,\n",
              " -0.01374772097915411,\n",
              " 0.03781634569168091,\n",
              " -0.015076442621648312,\n",
              " -0.0145783182233572,\n",
              " -0.012429311871528625,\n",
              " -0.05112070590257645,\n",
              " 0.042674072086811066,\n",
              " -0.03859506547451019,\n",
              " 0.0258342158049345,\n",
              " -0.0033613459672778845,\n",
              " -0.008885742165148258,\n",
              " 0.009936174377799034,\n",
              " 0.008650175295770168,\n",
              " -0.030997151508927345,\n",
              " 0.02414288930594921,\n",
              " 0.019081875681877136,\n",
              " 0.021299712359905243,\n",
              " -0.0016012733103707433,\n",
              " -0.03776213154196739,\n",
              " -0.007063841447234154,\n",
              " -0.010149193927645683,\n",
              " 0.018930433318018913,\n",
              " -0.030712800100445747,\n",
              " -0.0070159053429961205,\n",
              " -0.016985133290290833,\n",
              " 0.07048439234495163,\n",
              " 0.004174362868070602,\n",
              " -0.0022258968092501163,\n",
              " -0.02214689739048481,\n",
              " 0.027761224657297134,\n",
              " 0.034946225583553314,\n",
              " -0.044282216578722,\n",
              " -0.034360796213150024,\n",
              " -0.03490037843585014,\n",
              " 0.018017347902059555,\n",
              " -0.04288153350353241,\n",
              " 0.08776484429836273,\n",
              " 0.036676447838544846,\n",
              " -0.004171433392912149,\n",
              " -0.023275645449757576,\n",
              " -0.07430888712406158,\n",
              " -0.05915144830942154,\n",
              " 0.09232326596975327,\n",
              " -0.025909466668963432,\n",
              " -0.048947375267744064,\n",
              " -0.04248259216547012,\n",
              " -0.008888361044228077,\n",
              " -0.03014891780912876,\n",
              " -0.04645727202296257,\n",
              " -0.012320748530328274,\n",
              " -0.05791699141263962,\n",
              " -0.031029148027300835,\n",
              " -0.008003050461411476,\n",
              " 0.06263463944196701,\n",
              " -0.0003443692403379828,\n",
              " -0.0023389095440506935,\n",
              " -0.024600928649306297,\n",
              " -0.012160244397819042,\n",
              " 0.024075577035546303,\n",
              " 0.04455995932221413,\n",
              " -0.034846968948841095,\n",
              " 0.003009699983522296,\n",
              " -0.006747885141521692,\n",
              " 0.033100686967372894,\n",
              " 0.017554784193634987,\n",
              " 0.0066912914626300335,\n",
              " -0.03815562650561333,\n",
              " 0.03287581354379654,\n",
              " 0.008438421413302422,\n",
              " 0.05949356034398079,\n",
              " 0.05250370502471924,\n",
              " -0.025399159640073776,\n",
              " -0.00804033875465393,\n",
              " -0.0951286181807518,\n",
              " 0.04880988597869873,\n",
              " -0.030327320098876953,\n",
              " -0.00582280196249485,\n",
              " 0.06371273845434189,\n",
              " -0.008379978127777576,\n",
              " -0.01847619190812111,\n",
              " 0.0033510157372802496,\n",
              " -0.06536964327096939,\n",
              " -0.007209788542240858,\n",
              " 0.0060051498003304005,\n",
              " 0.00125016737729311,\n",
              " 0.0346645750105381,\n",
              " -0.0015321788378059864,\n",
              " -0.0008062190026976168,\n",
              " 0.012339606881141663,\n",
              " 0.004700178746134043,\n",
              " -0.014207116328179836,\n",
              " 0.048131342977285385,\n",
              " -0.028085095807909966,\n",
              " 0.0396636538207531,\n",
              " -0.026388678699731827,\n",
              " 0.02602994255721569,\n",
              " 0.005051842425018549,\n",
              " 0.061865344643592834,\n",
              " 0.07961132377386093,\n",
              " -0.03165215626358986,\n",
              " -0.019245469942688942,\n",
              " 0.047423698008060455,\n",
              " 0.029522284865379333,\n",
              " 0.0305622685700655,\n",
              " -0.04864562675356865,\n",
              " -0.05137154087424278,\n",
              " -0.03016076795756817,\n",
              " -0.010218193754553795,\n",
              " 0.02187609300017357,\n",
              " 0.06728222966194153,\n",
              " -0.058545537292957306,\n",
              " -0.07691137492656708,\n",
              " -0.04078034684062004,\n",
              " 0.02178112603724003,\n",
              " 0.004406917840242386,\n",
              " 0.01251312531530857,\n",
              " -0.01934864930808544,\n",
              " -0.00024852779461070895,\n",
              " -0.027734138071537018,\n",
              " 0.044431790709495544,\n",
              " 0.02758478745818138,\n",
              " 0.044154103845357895,\n",
              " -0.03837814927101135,\n",
              " 0.032868776470422745,\n",
              " 0.009355633519589901,\n",
              " -0.007741476874798536,\n",
              " -0.024058016017079353,\n",
              " -0.02246076613664627,\n",
              " -0.004031325690448284,\n",
              " -0.036114875227212906,\n",
              " 0.058158028870821,\n",
              " 0.0031521052587777376,\n",
              " 0.03671975061297417,\n",
              " -0.026520084589719772,\n",
              " -0.06631795316934586,\n",
              " 0.10039965808391571,\n",
              " -0.002299437765032053,\n",
              " -0.011070421896874905,\n",
              " -0.027540046721696854,\n",
              " 0.0407177172601223,\n",
              " 0.06292594969272614,\n",
              " 0.032785814255476,\n",
              " 0.021106448024511337,\n",
              " -0.04404228925704956,\n",
              " -0.005727207753807306,\n",
              " 0.06395310908555984,\n",
              " -0.007708157878369093]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents,                         #ismain hum documents jo ooper humne diye hain oski emdedding vector kerke hum store kerre hain apnay vector database joky chroma hai\n",
        "    embedding=embeddings) #humne isko yeh iss wajah se kerra hai ke agr hum isko vector database main store na kerte toh humain saray kaam khud kerne partay mtlb. cosine similarity waghera"
      ],
      "metadata": {
        "id": "3gKZ0q6646h4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dir(vectorstore)) #When you run list(dir(vectorstore)), it will return all the attributes and methods available for the vectorstore"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EYNwpZz6l4Z",
        "outputId": "8c1afff7-8a73-44a3-ecdf-88c63ee11f1e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'similarity_search_with_vectors',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore #The vectorstore object refers to a vector database that stores the embeddings (vectors) generated by your embedding model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBC8pnqI6p3o",
        "outputId": "daab9b5d-52dd-4ebf-b359-2c93559f0ad0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7fb7801ceb90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search(\"cat\") #similarity check kerra hai, cat word ki"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KLct5rY7RHT",
        "outputId": "1046f57d-68fe-4598-f6fd-804cb63612ba"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='eb0b2862-61af-470d-bc93-07a37dae338d', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(id='a51324b7-7c1c-499e-98b4-8ef5030f069a', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(id='461b99e1-f79e-4ead-9667-0690d23e6b22', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='79314213-92e2-4099-8353-718907a22530', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await vectorstore.asimilarity_search(\"cat\") #same cheez kerega, ooper walay search ki trhan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWCwvNOb92xF",
        "outputId": "2aaa244a-480b-4dfc-b4c1-cab3b74f1a1d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='eb0b2862-61af-470d-bc93-07a37dae338d', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(id='a51324b7-7c1c-499e-98b4-8ef5030f069a', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(id='461b99e1-f79e-4ead-9667-0690d23e6b22', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='79314213-92e2-4099-8353-718907a22530', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that providers implement different scores; Chroma here\n",
        "# returns a distance metric that should vary inversely with\n",
        "# similarity.\n",
        "\n",
        "vectorstore.similarity_search_with_score(\"cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TGGgbnR-hW-",
        "outputId": "38fee120-809b-4ef6-e30d-82fac8198e40"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(id='eb0b2862-61af-470d-bc93-07a37dae338d', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              "  0.6688324213027954),\n",
              " (Document(id='a51324b7-7c1c-499e-98b4-8ef5030f069a', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              "  0.9940857887268066),\n",
              " (Document(id='461b99e1-f79e-4ead-9667-0690d23e6b22', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              "  1.103921890258789),\n",
              " (Document(id='79314213-92e2-4099-8353-718907a22530', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              "  1.1072404384613037)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = embeddings.embed_query(\"cat\")# convert cat into vector\n",
        "\n",
        "vectorstore.similarity_search_by_vector(embedding) #and search here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYLmYH7i_lFS",
        "outputId": "edd798eb-8a97-4e39-f362-c34d3d408abf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='eb0b2862-61af-470d-bc93-07a37dae338d', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(id='a51324b7-7c1c-499e-98b4-8ef5030f069a', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(id='461b99e1-f79e-4ead-9667-0690d23e6b22', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='79314213-92e2-4099-8353-718907a22530', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YUZ3LBa8_qff",
        "outputId": "9dd4abde-5011-423c-8c8d-d787508dc813"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.014495342038571835,\n",
              " -0.004356286954134703,\n",
              " 0.030960695818066597,\n",
              " -0.01937987469136715,\n",
              " 0.046561747789382935,\n",
              " 0.07971760630607605,\n",
              " 0.044616784900426865,\n",
              " -0.019115572795271873,\n",
              " 0.08993305265903473,\n",
              " 0.05842595174908638,\n",
              " -0.0453537255525589,\n",
              " 0.018237140029668808,\n",
              " 0.08033973723649979,\n",
              " 0.02752574160695076,\n",
              " -0.028318511322140694,\n",
              " -0.02716362290084362,\n",
              " 0.006191493012011051,\n",
              " 0.005197346676141024,\n",
              " -0.01692069135606289,\n",
              " 0.03503800556063652,\n",
              " 0.08894353359937668,\n",
              " -0.010495638474822044,\n",
              " 0.04114319011569023,\n",
              " -0.01638908125460148,\n",
              " -0.03600003570318222,\n",
              " 0.01174926944077015,\n",
              " 0.03139335289597511,\n",
              " 0.03141077607870102,\n",
              " -0.0031625358387827873,\n",
              " -0.016714120283722878,\n",
              " 0.042587678879499435,\n",
              " 0.04249170795083046,\n",
              " 0.01343710720539093,\n",
              " 0.02279532328248024,\n",
              " 0.0567803755402565,\n",
              " -0.01019603107124567,\n",
              " -0.014729867689311504,\n",
              " 0.06853161752223969,\n",
              " -0.008628561161458492,\n",
              " -0.022934652864933014,\n",
              " -0.03452526405453682,\n",
              " 0.01392278727144003,\n",
              " -0.022488689050078392,\n",
              " 0.02131492830812931,\n",
              " -0.01229527685791254,\n",
              " 0.02273530140519142,\n",
              " 0.026013249531388283,\n",
              " 0.054191142320632935,\n",
              " -0.019599685445427895,\n",
              " 0.028602680191397667,\n",
              " 0.03854745998978615,\n",
              " 0.057732827961444855,\n",
              " -0.011696861125528812,\n",
              " 0.03517353534698486,\n",
              " -0.03327692300081253,\n",
              " -0.023202788084745407,\n",
              " -0.03749627247452736,\n",
              " -0.043892234563827515,\n",
              " 0.027108289301395416,\n",
              " 0.03884704411029816,\n",
              " 0.05957861244678497,\n",
              " 0.03194914013147354,\n",
              " 0.04493435472249985,\n",
              " 0.018000636249780655,\n",
              " 0.0012458269484341145,\n",
              " -0.05043290555477142,\n",
              " -0.007925835438072681,\n",
              " 0.029667330905795097,\n",
              " -0.041334379464387894,\n",
              " 0.04302045702934265,\n",
              " -0.065669484436512,\n",
              " 0.012996182776987553,\n",
              " -0.06907743215560913,\n",
              " 0.06380390375852585,\n",
              " -0.06687374413013458,\n",
              " -0.004804658703505993,\n",
              " 0.03108067996799946,\n",
              " 0.010110396891832352,\n",
              " 0.013045981526374817,\n",
              " -0.0013597144279628992,\n",
              " -0.025310993194580078,\n",
              " -0.016427835449576378,\n",
              " 0.12784525752067566,\n",
              " 0.0562836118042469,\n",
              " 0.03940841555595398,\n",
              " 0.010673423297703266,\n",
              " 0.044212907552719116,\n",
              " 0.048849403858184814,\n",
              " -0.029595036059617996,\n",
              " 0.018391147255897522,\n",
              " 0.032150592654943466,\n",
              " 0.0052758133970201015,\n",
              " 0.036253951489925385,\n",
              " 0.011419572867453098,\n",
              " 0.09523913264274597,\n",
              " -0.016540775075554848,\n",
              " -0.11345330625772476,\n",
              " -0.03300795704126358,\n",
              " -0.009019090794026852,\n",
              " -0.007627598475664854,\n",
              " -0.022728251293301582,\n",
              " 0.008672826923429966,\n",
              " -0.023972366005182266,\n",
              " -0.04063356667757034,\n",
              " 0.05192171782255173,\n",
              " 0.03169471397995949,\n",
              " 0.023015039041638374,\n",
              " 0.018516376614570618,\n",
              " -0.06874707341194153,\n",
              " 0.012852507643401623,\n",
              " 0.018752826377749443,\n",
              " -0.034104835242033005,\n",
              " -0.029502661898732185,\n",
              " 0.01095086894929409,\n",
              " 0.017953800037503242,\n",
              " 0.06737758964300156,\n",
              " -0.04356754571199417,\n",
              " 0.02228250727057457,\n",
              " -0.04604680463671684,\n",
              " -0.01731697842478752,\n",
              " 0.015446624718606472,\n",
              " -0.042186420410871506,\n",
              " -0.032552171498537064,\n",
              " -0.013582481071352959,\n",
              " 0.03246605396270752,\n",
              " -0.016573838889598846,\n",
              " -0.024401187896728516,\n",
              " -0.0072038196958601475,\n",
              " -0.07549452036619186,\n",
              " -0.009203414432704449,\n",
              " 0.02896364964544773,\n",
              " -0.10613583028316498,\n",
              " 0.03781411796808243,\n",
              " 0.040271855890750885,\n",
              " -0.012917520478367805,\n",
              " -0.014856315217912197,\n",
              " -0.002216820605099201,\n",
              " -0.042743101716041565,\n",
              " 0.017111534252762794,\n",
              " 0.005375030916184187,\n",
              " -0.021967323496937752,\n",
              " -0.023669961839914322,\n",
              " -0.05614436790347099,\n",
              " 0.036794159561395645,\n",
              " 0.007754378020763397,\n",
              " 0.013125460594892502,\n",
              " -0.013753363862633705,\n",
              " 0.02151157520711422,\n",
              " 0.02284136228263378,\n",
              " 0.05279908701777458,\n",
              " -0.01927850767970085,\n",
              " -0.040149297565221786,\n",
              " -0.029326194897294044,\n",
              " -0.0826430469751358,\n",
              " -0.005802650470286608,\n",
              " 0.03755241632461548,\n",
              " 0.056654009968042374,\n",
              " -0.046860672533512115,\n",
              " 0.012279239483177662,\n",
              " -0.012804095633327961,\n",
              " -0.008213716559112072,\n",
              " 0.015394221991300583,\n",
              " -0.019039791077375412,\n",
              " 0.0004277710395399481,\n",
              " -0.03749733045697212,\n",
              " 0.004896875936537981,\n",
              " 0.006666247732937336,\n",
              " -0.0368269719183445,\n",
              " 0.006604892201721668,\n",
              " -0.041655901819467545,\n",
              " -0.015426828525960445,\n",
              " -0.026914777234196663,\n",
              " -0.033153023570775986,\n",
              " -0.006163540296256542,\n",
              " -0.043462660163640976,\n",
              " 0.03373173996806145,\n",
              " -0.022072628140449524,\n",
              " -0.059182554483413696,\n",
              " -0.04107022285461426,\n",
              " -0.011897679418325424,\n",
              " 0.0894283875823021,\n",
              " -0.010708942078053951,\n",
              " 0.0030413600616157055,\n",
              " -0.05152417719364166,\n",
              " -0.021752290427684784,\n",
              " 0.0021489188075065613,\n",
              " -0.032366637140512466,\n",
              " 0.04301592707633972,\n",
              " -0.014634218066930771,\n",
              " 0.004646045155823231,\n",
              " -0.03228824958205223,\n",
              " -0.030899638310074806,\n",
              " 0.034567225724458694,\n",
              " -0.029848938807845116,\n",
              " 0.007353954948484898,\n",
              " 0.029665948823094368,\n",
              " 0.05472755432128906,\n",
              " -0.056341275572776794,\n",
              " 0.02834026888012886,\n",
              " 0.01007724180817604,\n",
              " 0.07145177572965622,\n",
              " 0.014313459396362305,\n",
              " 0.03674114868044853,\n",
              " -0.03532882407307625,\n",
              " -0.03655190020799637,\n",
              " 0.004517338238656521,\n",
              " -0.02057579904794693,\n",
              " -0.04629502817988396,\n",
              " 0.04579285904765129,\n",
              " 0.02886699140071869,\n",
              " -0.0479821041226387,\n",
              " 0.02997475303709507,\n",
              " -0.025145582854747772,\n",
              " -0.024457167834043503,\n",
              " -0.044499240815639496,\n",
              " -0.013999933376908302,\n",
              " 0.017638012766838074,\n",
              " -0.005100300069898367,\n",
              " 0.050823409110307693,\n",
              " -0.017096595838665962,\n",
              " 0.028085004538297653,\n",
              " 0.007485541515052319,\n",
              " 0.04336225986480713,\n",
              " -0.023835768923163414,\n",
              " 0.05174798145890236,\n",
              " -0.0036513807717710733,\n",
              " -0.03772061690688133,\n",
              " -0.009190001524984837,\n",
              " 0.05010225996375084,\n",
              " -0.028060661628842354,\n",
              " -0.005852084141224623,\n",
              " 0.0586034432053566,\n",
              " 0.02624264545738697,\n",
              " -0.03800287842750549,\n",
              " -0.0008826943812891841,\n",
              " 0.022417888045310974,\n",
              " -0.004312317818403244,\n",
              " -0.06868863105773926,\n",
              " 0.032671067863702774,\n",
              " -0.0022994743194431067,\n",
              " 0.0007701306021772325,\n",
              " -0.023832449689507484,\n",
              " 0.03522908315062523,\n",
              " 0.01721302978694439,\n",
              " 0.03291720896959305,\n",
              " 0.011703910306096077,\n",
              " 0.016229702159762383,\n",
              " 0.11202928423881531,\n",
              " -0.012567290104925632,\n",
              " -0.028998728841543198,\n",
              " -0.01796942949295044,\n",
              " -0.007563501130789518,\n",
              " 0.019764240831136703,\n",
              " -0.03755462169647217,\n",
              " -0.007266667205840349,\n",
              " -0.033096350729465485,\n",
              " -0.0011382579104974866,\n",
              " 0.01661369390785694,\n",
              " 0.01625390723347664,\n",
              " -0.0527925081551075,\n",
              " -0.0005613145767711103,\n",
              " 0.014885400421917439,\n",
              " -0.05623757094144821,\n",
              " -0.06841340661048889,\n",
              " -0.04774221405386925,\n",
              " -0.09854623675346375,\n",
              " 0.050990991294384,\n",
              " -0.01567322388291359,\n",
              " 0.05277993902564049,\n",
              " -0.03459024429321289,\n",
              " 0.01863996870815754,\n",
              " 0.015093546360731125,\n",
              " -0.05867292732000351,\n",
              " 0.01694985292851925,\n",
              " -0.03468502312898636,\n",
              " 0.03431730717420578,\n",
              " 0.01681828685104847,\n",
              " 0.009453254751861095,\n",
              " -0.0314871110022068,\n",
              " -0.03418149799108505,\n",
              " 0.02665816619992256,\n",
              " -0.020313439890742302,\n",
              " 0.029595443978905678,\n",
              " 0.015466163866221905,\n",
              " -0.0043038055300712585,\n",
              " -0.09575702995061874,\n",
              " -0.01698094606399536,\n",
              " -0.02044876478612423,\n",
              " -0.07961999624967575,\n",
              " 0.02469290792942047,\n",
              " -0.02415757067501545,\n",
              " -0.012890279293060303,\n",
              " -0.0005242861807346344,\n",
              " -0.07397239655256271,\n",
              " 0.026003509759902954,\n",
              " 0.01713055931031704,\n",
              " 0.01858633942902088,\n",
              " 0.02493404597043991,\n",
              " 0.007078996859490871,\n",
              " -0.042431220412254333,\n",
              " 0.03442830592393875,\n",
              " 0.03028200753033161,\n",
              " -0.04095824062824249,\n",
              " -0.018567312508821487,\n",
              " -0.04660164564847946,\n",
              " -0.014636268839240074,\n",
              " 0.06386875361204147,\n",
              " -6.676342309219763e-05,\n",
              " -0.06168491020798683,\n",
              " 0.029985416680574417,\n",
              " 0.04212134703993797,\n",
              " 0.04766783118247986,\n",
              " -0.023553142324090004,\n",
              " 0.012756011448800564,\n",
              " -0.006004644092172384,\n",
              " 0.024423105642199516,\n",
              " -0.12709251046180725,\n",
              " 0.0053990245796740055,\n",
              " -0.018125269562005997,\n",
              " -0.004389484878629446,\n",
              " 0.007763621862977743,\n",
              " -0.001605904079042375,\n",
              " -0.07371946424245834,\n",
              " 0.026210224255919456,\n",
              " 0.015298396348953247,\n",
              " -0.030079368501901627,\n",
              " 0.03138217329978943,\n",
              " 0.0016951576108112931,\n",
              " -0.0025201758835464716,\n",
              " 0.028197355568408966,\n",
              " 0.03749537467956543,\n",
              " 0.033992502838373184,\n",
              " -0.043073005974292755,\n",
              " -0.031338341534137726,\n",
              " -0.010517865419387817,\n",
              " -0.009557870216667652,\n",
              " -0.004246994853019714,\n",
              " 0.019957145676016808,\n",
              " 0.061667490750551224,\n",
              " -0.03625188022851944,\n",
              " 0.043662674725055695,\n",
              " 0.045630957931280136,\n",
              " -0.027949176728725433,\n",
              " 0.03632242605090141,\n",
              " -0.04164774343371391,\n",
              " -0.05566929280757904,\n",
              " -0.014871735125780106,\n",
              " -0.009267404675483704,\n",
              " 0.0297231525182724,\n",
              " -0.03755731135606766,\n",
              " -0.002444678219035268,\n",
              " 0.05032859742641449,\n",
              " 0.06653160601854324,\n",
              " 0.03581548482179642,\n",
              " 0.02291916310787201,\n",
              " 0.007579154334962368,\n",
              " 0.052164290100336075,\n",
              " 0.027341725304722786,\n",
              " 0.029429402202367783,\n",
              " -0.05082295089960098,\n",
              " 0.00852219294756651,\n",
              " 0.03701968491077423,\n",
              " -0.021862531080842018,\n",
              " 0.0066058156080543995,\n",
              " 0.010817384347319603,\n",
              " -0.013875287026166916,\n",
              " 0.03772403672337532,\n",
              " 0.01746552623808384,\n",
              " -0.04079204797744751,\n",
              " -0.017093703150749207,\n",
              " 0.02326754666864872,\n",
              " 0.03330978378653526,\n",
              " -0.061781056225299835,\n",
              " -0.056202881038188934,\n",
              " 0.03451331704854965,\n",
              " 0.0193772092461586,\n",
              " 0.026546454057097435,\n",
              " -0.010458791628479958,\n",
              " 0.010780589655041695,\n",
              " -0.06542893499135971,\n",
              " -0.049370113760232925,\n",
              " -0.025627417489886284,\n",
              " -0.03826787695288658,\n",
              " 0.03643171489238739,\n",
              " -0.011802082881331444,\n",
              " 0.025972934439778328,\n",
              " -0.013640172779560089,\n",
              " -0.01863125152885914,\n",
              " -0.005353703163564205,\n",
              " 0.048920925706624985,\n",
              " -0.0036599019076675177,\n",
              " 0.07777836918830872,\n",
              " -0.007352809887379408,\n",
              " 0.0941699743270874,\n",
              " 0.004023346118628979,\n",
              " 0.04038522019982338,\n",
              " 0.0062688011676073074,\n",
              " 0.017891239374876022,\n",
              " -0.00045396244968287647,\n",
              " -0.005121137946844101,\n",
              " 0.01605778932571411,\n",
              " -0.02151099033653736,\n",
              " 0.05888630449771881,\n",
              " -0.03158915415406227,\n",
              " -0.02463885210454464,\n",
              " -0.060618676245212555,\n",
              " 0.08029492199420929,\n",
              " 0.015040358528494835,\n",
              " 0.023191051557660103,\n",
              " 0.013043473474681377,\n",
              " -0.008983276784420013,\n",
              " -0.01960049197077751,\n",
              " 0.003931979648768902,\n",
              " -0.004162451718002558,\n",
              " -0.0558016262948513,\n",
              " -0.02321023680269718,\n",
              " -0.008982245810329914,\n",
              " -0.03250500187277794,\n",
              " 0.013700757175683975,\n",
              " -0.020671239122748375,\n",
              " -0.01966019533574581,\n",
              " -0.026049116626381874,\n",
              " 0.023425033316016197,\n",
              " -0.0571289137005806,\n",
              " 0.0676134005188942,\n",
              " -0.03147856891155243,\n",
              " 0.004783484153449535,\n",
              " -0.02105563133955002,\n",
              " 0.023404225707054138,\n",
              " 0.009986902587115765,\n",
              " 0.03884095698595047,\n",
              " 0.052581023424863815,\n",
              " -0.051760319620370865,\n",
              " -0.07683192938566208,\n",
              " 0.044021718204021454,\n",
              " -0.01597711443901062,\n",
              " -0.031912315636873245,\n",
              " 0.0016009911196306348,\n",
              " 0.01622863858938217,\n",
              " 0.044367995113134384,\n",
              " -0.05448080226778984,\n",
              " -0.007903790101408958,\n",
              " 0.0320221483707428,\n",
              " 0.04898742586374283,\n",
              " -0.0075828200206160545,\n",
              " -0.03480053320527077,\n",
              " 0.0369291678071022,\n",
              " 0.011668612249195576,\n",
              " 0.024968495592474937,\n",
              " -0.06261155754327774,\n",
              " -0.015086617320775986,\n",
              " -0.010135887190699577,\n",
              " 0.03757711499929428,\n",
              " -0.022884149104356766,\n",
              " -0.024589966982603073,\n",
              " 0.001826342660933733,\n",
              " -0.038321904838085175,\n",
              " 0.04672980308532715,\n",
              " -0.003363755065947771,\n",
              " 0.0018584695644676685,\n",
              " -0.03724170848727226,\n",
              " -0.01473590824753046,\n",
              " 0.07581968605518341,\n",
              " 0.0446288138628006,\n",
              " 0.012080879881978035,\n",
              " -0.0015126736834645271,\n",
              " -0.034375134855508804,\n",
              " 0.020515387877821922,\n",
              " -0.025188425555825233,\n",
              " 0.033369239419698715,\n",
              " -0.020310256630182266,\n",
              " 0.03177556395530701,\n",
              " -0.0025869293604046106,\n",
              " -0.0023815983440726995,\n",
              " -0.06960627436637878,\n",
              " 0.016432374715805054,\n",
              " -0.03503098711371422,\n",
              " -0.007198856677860022,\n",
              " 0.018458737060427666,\n",
              " 0.012718822807073593,\n",
              " -0.0018746207933872938,\n",
              " 0.026161249727010727,\n",
              " -0.016911398619413376,\n",
              " -0.012264116667211056,\n",
              " 0.009560879319906235,\n",
              " -0.02717251516878605,\n",
              " -0.04450945183634758,\n",
              " -0.005724712274968624,\n",
              " 0.00856366939842701,\n",
              " -0.004699807148426771,\n",
              " 0.02714575082063675,\n",
              " 0.03769371286034584,\n",
              " -0.014445687644183636,\n",
              " -0.05889250338077545,\n",
              " -0.027744397521018982,\n",
              " -0.016285041347146034,\n",
              " 0.03391817584633827,\n",
              " 0.04765716567635536,\n",
              " -0.03588756173849106,\n",
              " -0.009045683778822422,\n",
              " 0.06427288055419922,\n",
              " 0.008041891269385815,\n",
              " -0.012796709313988686,\n",
              " 0.0059231845661997795,\n",
              " -0.03066275268793106,\n",
              " -0.019198721274733543,\n",
              " 0.0025056852027773857,\n",
              " -0.011243964545428753,\n",
              " 0.015078474767506123,\n",
              " 0.00023229068028740585,\n",
              " 0.03704901412129402,\n",
              " -0.03782195597887039,\n",
              " 0.03684953600168228,\n",
              " -0.0008073574863374233,\n",
              " -0.0007802497711963952,\n",
              " 0.0031752989161759615,\n",
              " -0.05408695712685585,\n",
              " 0.013624279759824276,\n",
              " -0.03340109437704086,\n",
              " 0.008810549974441528,\n",
              " -0.06255199760198593,\n",
              " 0.0035539439413696527,\n",
              " 0.04046516865491867,\n",
              " -0.02408730424940586,\n",
              " -0.004444975405931473,\n",
              " -0.03216514363884926,\n",
              " 0.042588748037815094,\n",
              " 0.03194030374288559,\n",
              " 0.046359553933143616,\n",
              " -0.011274408549070358,\n",
              " -0.015195063315331936,\n",
              " 0.0842229500412941,\n",
              " 0.04184433072805405,\n",
              " 0.029512617737054825,\n",
              " -0.001792022492736578,\n",
              " 0.017622148618102074,\n",
              " 0.0037141661159694195,\n",
              " -0.04364081472158432,\n",
              " -0.0154451048001647,\n",
              " 0.014997771941125393,\n",
              " 0.02684319205582142,\n",
              " -0.01711355708539486,\n",
              " 0.026975281536579132,\n",
              " 0.0010606914293020964,\n",
              " -0.02851109765470028,\n",
              " 0.013734688982367516,\n",
              " 0.023280879482626915,\n",
              " -0.00656582647934556,\n",
              " -0.005111082922667265,\n",
              " 0.06002664566040039,\n",
              " -0.017135845497250557,\n",
              " -0.04625414311885834,\n",
              " -0.04910166561603546,\n",
              " -0.014541546814143658,\n",
              " -0.04936428740620613,\n",
              " 0.0008820245275273919,\n",
              " 0.010460282675921917,\n",
              " -0.02102917619049549,\n",
              " -0.02600373886525631,\n",
              " 0.06381511688232422,\n",
              " 0.0018244379898533225,\n",
              " -0.015527045354247093,\n",
              " 0.006495023611932993,\n",
              " 0.017078131437301636,\n",
              " 0.021536266431212425,\n",
              " 0.0223929975181818,\n",
              " -0.010455809533596039,\n",
              " 0.047650277614593506,\n",
              " -0.0423312745988369,\n",
              " -0.035175591707229614,\n",
              " 0.03393815457820892,\n",
              " -0.0018116110004484653,\n",
              " -0.018686875700950623,\n",
              " 0.003949502017349005,\n",
              " 0.047485873103141785,\n",
              " 0.040419384837150574,\n",
              " -0.04728281870484352,\n",
              " -0.010295979678630829,\n",
              " 0.014262603595852852,\n",
              " 0.004259874112904072,\n",
              " -0.030744392424821854,\n",
              " 0.013242265209555626,\n",
              " 0.0467415377497673,\n",
              " -0.031172893941402435,\n",
              " -0.06415993720293045,\n",
              " 0.006083221640437841,\n",
              " -0.025612847879529,\n",
              " -0.017075881361961365,\n",
              " 0.004445577971637249,\n",
              " -0.017920581623911858,\n",
              " -0.04836912825703621,\n",
              " 0.023618679493665695,\n",
              " 0.013154268264770508,\n",
              " -0.06432593613862991,\n",
              " 0.02045198157429695,\n",
              " -0.06145953759551048,\n",
              " 0.0196923166513443,\n",
              " 0.00812553521245718,\n",
              " 0.05251162871718407,\n",
              " 0.03422452136874199,\n",
              " -0.023353496566414833,\n",
              " -0.05157572776079178,\n",
              " 0.01932789385318756,\n",
              " 0.0206427164375782,\n",
              " -0.00753538403660059,\n",
              " -0.004960597492754459,\n",
              " -0.01940508559346199,\n",
              " -0.048446159809827805,\n",
              " 0.01647992804646492,\n",
              " 0.009138318710029125,\n",
              " -0.046364326030015945,\n",
              " -0.006677676923573017,\n",
              " -0.03899603709578514,\n",
              " -0.04417090490460396,\n",
              " -0.04246145114302635,\n",
              " 0.0019707854371517897,\n",
              " -0.0732458084821701,\n",
              " -0.028470469638705254,\n",
              " 0.06270482391119003,\n",
              " -0.007610340137034655,\n",
              " -0.020705873146653175,\n",
              " -0.007499265018850565,\n",
              " 0.04953429847955704,\n",
              " -0.05480872839689255,\n",
              " -0.07341049611568451,\n",
              " 0.0029613978695124388,\n",
              " -0.00868128053843975,\n",
              " -0.013636158779263496,\n",
              " -0.006363636814057827,\n",
              " -0.0295990202575922,\n",
              " -0.04738885164260864,\n",
              " 0.024345602840185165,\n",
              " 0.02689945511519909,\n",
              " 0.060283202677965164,\n",
              " -0.05194453150033951,\n",
              " -0.00316982576623559,\n",
              " 0.023382510989904404,\n",
              " -0.017933974042534828,\n",
              " -0.025890206918120384,\n",
              " -0.04840443655848503,\n",
              " -0.015405340120196342,\n",
              " 0.04982003942131996,\n",
              " 0.008434398099780083,\n",
              " 0.061632975935935974,\n",
              " -0.043821316212415695,\n",
              " 0.01619947887957096,\n",
              " 0.027641762048006058,\n",
              " 0.0005397460190579295,\n",
              " -0.006916711572557688,\n",
              " 0.03270827233791351,\n",
              " -0.006939973682165146,\n",
              " 0.007771560922265053,\n",
              " -0.03916696086525917,\n",
              " -0.013202338479459286,\n",
              " -0.05303141847252846,\n",
              " 0.00993372779339552,\n",
              " -0.03915252164006233,\n",
              " -0.023788580670952797,\n",
              " 0.004321413114666939,\n",
              " 0.004640771541744471,\n",
              " -0.04862729832530022,\n",
              " -0.043637678027153015,\n",
              " -0.01829393208026886,\n",
              " 0.018183691427111626,\n",
              " -0.01472838968038559,\n",
              " -0.026670178398489952,\n",
              " -0.0344395712018013,\n",
              " 0.032019827514886856,\n",
              " 0.01825467124581337,\n",
              " -0.04060547426342964,\n",
              " 0.016212722286581993,\n",
              " 0.05365429073572159,\n",
              " 0.0398184135556221,\n",
              " 0.04877550154924393,\n",
              " -0.05641520023345947,\n",
              " 0.020684603601694107,\n",
              " -0.00805574469268322,\n",
              " -0.03198995441198349,\n",
              " -0.04015467315912247,\n",
              " 0.032035645097494125,\n",
              " -7.323707541218027e-05,\n",
              " -0.06813272833824158,\n",
              " 0.04268966615200043,\n",
              " 0.035583265125751495,\n",
              " 0.0023574193473905325,\n",
              " 0.013166993856430054,\n",
              " 0.034896120429039,\n",
              " -0.011006330139935017,\n",
              " -0.051365114748477936,\n",
              " -0.008262085728347301,\n",
              " -0.010505313985049725,\n",
              " 0.011138434521853924,\n",
              " -0.04577609524130821,\n",
              " 0.03484855964779854,\n",
              " -0.008504487574100494,\n",
              " -0.003009496256709099,\n",
              " -0.046396855264902115,\n",
              " 0.0727643296122551,\n",
              " -0.056962523609399796,\n",
              " 0.023479048162698746,\n",
              " -0.021565020084381104,\n",
              " -0.008273879997432232,\n",
              " -0.05476883798837662,\n",
              " -0.07189113646745682,\n",
              " 0.05023609474301338,\n",
              " -0.0134401461109519,\n",
              " 0.007842227816581726,\n",
              " 0.020003508776426315,\n",
              " -0.005303300451487303,\n",
              " 0.0071795242838561535,\n",
              " -0.02265780419111252,\n",
              " 0.06328634172677994,\n",
              " 0.01012442260980606,\n",
              " 0.032010436058044434,\n",
              " -0.013737544417381287,\n",
              " 0.010469690896570683,\n",
              " -0.0047478205524384975,\n",
              " 0.06512557715177536,\n",
              " 0.006134385708719492,\n",
              " -0.006611072923988104,\n",
              " -0.008178671821951866,\n",
              " -0.02132396586239338,\n",
              " 0.03307435289025307,\n",
              " 0.05339197814464569,\n",
              " 0.08201231807470322,\n",
              " 0.04520352929830551,\n",
              " -0.026250004768371582,\n",
              " 0.028347637504339218,\n",
              " 0.012580775655806065,\n",
              " 0.12949956953525543,\n",
              " 0.05566151440143585,\n",
              " 0.023507010191679,\n",
              " 0.028837144374847412,\n",
              " 0.05038142204284668,\n",
              " -0.033684078603982925,\n",
              " 0.034963689744472504,\n",
              " 0.006386245135217905,\n",
              " -0.03819866105914116,\n",
              " 0.011994732543826103,\n",
              " 0.007296890486031771,\n",
              " -0.013642748817801476,\n",
              " 0.024220913648605347,\n",
              " 0.014407324604690075,\n",
              " 0.019176321104168892,\n",
              " -0.013349624350667,\n",
              " 0.04442369565367699,\n",
              " -0.014851129613816738,\n",
              " -0.0032214985694736242,\n",
              " -0.00157309474889189,\n",
              " -0.03889244794845581,\n",
              " -0.015231824479997158,\n",
              " 0.08817324042320251,\n",
              " 0.013628846034407616,\n",
              " -0.02279551513493061,\n",
              " 0.045421943068504333,\n",
              " -0.015625517815351486,\n",
              " 0.047574929893016815,\n",
              " -0.002126862993463874,\n",
              " 0.06680796295404434,\n",
              " 0.034890275448560715,\n",
              " -0.01490753423422575,\n",
              " 0.0739324614405632,\n",
              " 0.011011652648448944,\n",
              " 0.04814859852194786,\n",
              " -0.06317641586065292,\n",
              " 0.0067360843531787395,\n",
              " -0.04438389465212822,\n",
              " 0.04865564405918121]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrievers"
      ],
      "metadata": {
        "id": "OZ1DrIZjAUWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "# Here, the RunnableLambda wraps the vectorstore.similarity_search function, making it reusable and easily configurable.\n",
        "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)  # select top result (pehle saray result ara tha, lekin ab top result dega sirf)\n",
        "\n",
        "retriever.batch([\"cat\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-asOSoFAXp7",
        "outputId": "99c51ccd-7049-42a0-c860-0bd11fcf741c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(id='eb0b2862-61af-470d-bc93-07a37dae338d', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "#yahan humary llm yeh jo hum use kerre hain yeh koi sa bhi ho skta hai iska koi lena dena nahi hai apnay embedding model se, btw embedding model apna ready hogya hai ooper\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",\n",
        "                             api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "hm-zlnceIJV3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ab neechay ab augment wala kaam kerre hain"
      ],
      "metadata": {
        "id": "uPyt74k5JEGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate #Purpose: Helps create structured and reusable templates for conversational AI models.\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "#humne llm ko restrict kerdia hai, aur kuch nahi dena\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fhpLvcuoI0W6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ],
      "metadata": {
        "id": "cIQPN8O3NTS1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG"
      ],
      "metadata": {
        "id": "uo2Kl4wRNoxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n",
        "           #line 35 per hai yeh^            #ooper wali line main humne runnable passthorugh bnaya hai jiske meaning hai directly apna question le aega |#ooper wala code le aega line 39 wala\n",
        "#yeh humne pehle osse PIPELINE bna ker dedi hai ke RAG ko kaam kis tareeqay se kerna hai\n",
        "\n",
        "\n",
        "# rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n",
        "             #this is is Retrieval    #this part is augment              #this part is generation\n"
      ],
      "metadata": {
        "id": "xvK9df0BNrjN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"tell me about shark\")\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "aQm-UMTnTZ2o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "b828b9cd-b458-4ddd-c8f2-eb184a5ab0c9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:293534312090'. [reason: \"RATE_LIMIT_EXCEEDED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"generativelanguage.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"quota_metric\"\n",
            "  value: \"generativelanguage.googleapis.com/generate_content_requests\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"quota_location\"\n",
            "  value: \"us-east1\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"quota_limit\"\n",
            "  value: \"GenerateContentRequestsPerMinutePerProjectPerRegion\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"quota_limit_value\"\n",
            "  value: \"0\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/293534312090\"\n",
            "}\n",
            ", links {\n",
            "  description: \"Request a higher quota limit.\"\n",
            "  url: \"https://cloud.google.com/docs/quotas/help/request_increase\"\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhausted",
          "evalue": "429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:293534312090'. [reason: \"RATE_LIMIT_EXCEEDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"quota_metric\"\n  value: \"generativelanguage.googleapis.com/generate_content_requests\"\n}\nmetadata {\n  key: \"quota_location\"\n  value: \"us-east1\"\n}\nmetadata {\n  key: \"quota_limit\"\n  value: \"GenerateContentRequestsPerMinutePerProjectPerRegion\"\n}\nmetadata {\n  key: \"quota_limit_value\"\n  value: \"0\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/293534312090\"\n}\n, links {\n  description: \"Request a higher quota limit.\"\n  url: \"https://cloud.google.com/docs/quotas/help/request_increase\"\n}\n]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-6af346949944>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tell me about shark\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         return cast(\n\u001b[1;32m    285\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    785\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         flattened_outputs = [\n\u001b[1;32m    645\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 results.append(\n\u001b[0;32m--> 633\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    634\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    852\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mtool_choice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_choice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         )\n\u001b[0;32m--> 951\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m             ) from e\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    831\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhausted\u001b[0m: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:293534312090'. [reason: \"RATE_LIMIT_EXCEEDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"quota_metric\"\n  value: \"generativelanguage.googleapis.com/generate_content_requests\"\n}\nmetadata {\n  key: \"quota_location\"\n  value: \"us-east1\"\n}\nmetadata {\n  key: \"quota_limit\"\n  value: \"GenerateContentRequestsPerMinutePerProjectPerRegion\"\n}\nmetadata {\n  key: \"quota_limit_value\"\n  value: \"0\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/293534312090\"\n}\n, links {\n  description: \"Request a higher quota limit.\"\n  url: \"https://cloud.google.com/docs/quotas/help/request_increase\"\n}\n]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FACE DETECTION WITH EMBEDDING"
      ],
      "metadata": {
        "id": "ArzkJ8aQg-Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch==2.5.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efP_qrrfiSJe",
        "outputId": "24fee363-184f-4857-ab96-b0813f063586",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.5.1\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
            "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.2\n",
            "    Uninstalling torch-2.2.2:\n",
            "      Successfully uninstalled torch-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires torch<2.3.0,>=2.2.0, but you have torch 2.5.1 which is incompatible.\n",
            "torchvision 0.17.2 requires torch==2.2.2, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.5.1 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7LdDPK7hBai",
        "outputId": "f010c05f-7c79-440f-b3b4-0eb95e46a1cc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2HxLIl-kKE2",
        "outputId": "412b055c-e288-45d9-9e5f-f254b6f3623c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/4.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/4.5 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/4.5 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m4.4/4.5 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 11.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "ojF9wQIckfOp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval() #pretrain model ka architecture ajaega\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2a9912f3cbf0467ca5d0e4360cce8ff9",
            "3c69dabe6825453586c59b058fc389dd",
            "36f6113aea0c4aa5ad0b9e6ef5df54ee",
            "7ac3e32ffe84417b972c43e77bb855aa",
            "e43af5fe1dd84abca8568402a1b6a1c5",
            "1688aef75357464ab808d68db66d93dd",
            "19175b5ce54948d7a169a51e5598a1c7",
            "3a303de07ac54a75b6899993c451609c",
            "94f665510f934dff8b03dd53c0cf98e7",
            "09d4d1d46e984d43938872406685a954",
            "a50ae2b971c14919984170ea9404e351"
          ]
        },
        "collapsed": true,
        "id": "DB_4dvFIqDow",
        "outputId": "3fe0191c-3b9b-4b19-c88f-6cfee4bc1cb0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a9912f3cbf0467ca5d0e4360cce8ff9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InceptionResnetV1(\n",
              "  (conv2d_1a): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2a): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2b): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2d_3b): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4a): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4b): BasicConv2d(\n",
              "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (repeat_1): Sequential(\n",
              "    (0): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_6a): Mixed_6a(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_2): Sequential(\n",
              "    (0): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_7a): Mixed_7a(\n",
              "    (branch0): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_3): Sequential(\n",
              "    (0): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (block8): Block8(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
              "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function to transform the image into a tensor\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    return preprocess(image).unsqueeze(0)\n",
        "\n",
        "# Function to create image embeddings\n",
        "def create_image_embedding(image_path):\n",
        "    try:\n",
        "        input_tensor = preprocess_image(image_path)\n",
        "        with torch.no_grad():\n",
        "            embeddings = model(input_tensor)# ebedding important line\n",
        "        return embeddings.squeeze().numpy()\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "UsXQ6l4-qlfF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "metadata": {
        "id": "epaIEbfRVZ-f"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create python function where we provide image url and imag_name then it save in images folder\n",
        "\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def save_image_from_url(image_url, image_name):\n",
        "  \"\"\"\n",
        "  Downloads an image from a URL and saves it to the 'images' folder.\n",
        "\n",
        "  Args:\n",
        "    image_url: The URL of the image to download.\n",
        "    image_name: The name of the file to save the image as.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if not os.path.exists(\"images\"):\n",
        "      os.makedirs(\"images\")\n",
        "\n",
        "    image_path = os.path.join(\"images\", image_name)\n",
        "\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    with open(image_path, 'wb') as file:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n",
        "\n",
        "    print(f\"Image saved to: {image_path}\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading image: {e}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "btRLlQjhV2eD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4E03AQEEn9DuNlQwvw/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1664654245747?e=2147483647&v=beta&t=NGB0a9aqsgdyxpbuO3rqws95ogJnL_6aRtBDS7IWPfw\",\"s1.jpg\")\n",
        "save_image_from_url(\"https://avatars.githubusercontent.com/u/10209765?v=4\", \"q1.jpg\")\n",
        "\n",
        "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4D22AQFmuEiR8ttUmw/feedshare-shrink_800/feedshare-shrink_800/0/1711203894556?e=2147483647&v=beta&t=GEZGp_cdogNJCJIGidoEw_DjW2FXZcG4nUUlaNF1Zlc\",\"z1.jpg\")\n",
        "save_image_from_url(\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQBBiqefc7Le97Rn0udVVBkur7RlU53FcQh1A&s\",'z2.jpg')\n",
        "save_image_from_url(\"https://scontent.fkhi4-4.fna.fbcdn.net/v/t39.30808-6/468785380_10160566910882765_300507882801991935_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeEk77SJKagGymTo3ibNnnx9YsjCm8DJ0lRiyMKbwMnSVMJqs7YWsJDuzKzXyLHLoFk&_nc_ohc=QJMm9K-AE4QQ7kNvgFE0N2o&_nc_oc=Adi1r8eogMcuDIMMLJvliCOnaaXQ2KnUbbJvY94aAnfInkDB-fyB_1ZXBpDQnWTkZnY&_nc_zt=23&_nc_ht=scontent.fkhi4-4.fna&_nc_gid=AcSynbwc6ukNTxWnUzjhtEe&oh=00_AYCvnF-vj63T-X69PZgBk6JvVjepzybVukgHPSM_6BXkGQ&oe=678003A4\",'s2.jpg')\n",
        "save_image_from_url(\"https://i.ytimg.com/vi/7QD3GKvSyMk/hqdefault.jpg?sqp=-oaymwEmCOADEOgC8quKqQMa8AEB-AHOBYAC0AWKAgwIABABGGUgXChPMA8=&rs=AOn4CLB2EaZsLrClGHqUMUhApQ_sxAcF7Q\",\"q2.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR5e9OSKV8bY",
        "outputId": "29d0f049-f6ab-485e-aa69-e94c9927ea32"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved to: images/s1.jpg\n",
            "Image saved to: images/q1.jpg\n",
            "Image saved to: images/z1.jpg\n",
            "Image saved to: images/z2.jpg\n",
            "Error downloading image: 403 Client Error: Forbidden for url: https://scontent.fkhi4-4.fna.fbcdn.net/v/t39.30808-6/468785380_10160566910882765_300507882801991935_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeEk77SJKagGymTo3ibNnnx9YsjCm8DJ0lRiyMKbwMnSVMJqs7YWsJDuzKzXyLHLoFk&_nc_ohc=QJMm9K-AE4QQ7kNvgFE0N2o&_nc_oc=Adi1r8eogMcuDIMMLJvliCOnaaXQ2KnUbbJvY94aAnfInkDB-fyB_1ZXBpDQnWTkZnY&_nc_zt=23&_nc_ht=scontent.fkhi4-4.fna&_nc_gid=AcSynbwc6ukNTxWnUzjhtEe&oh=00_AYCvnF-vj63T-X69PZgBk6JvVjepzybVukgHPSM_6BXkGQ&oe=678003A4\n",
            "Image saved to: images/q2.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_from_url(\"data:image/jpeg;base64,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\",\"q2.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv4Lfq5sWK6Q",
        "outputId": "7849e80c-b159-4b58-d7c1-8394fe3077fe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading image: No connection adapters were found for 'data:image/jpeg;base64,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'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "image_path = \"./images/q2.jpg\"\n",
        "q2 = create_image_embedding(image_path)\n",
        "\n",
        "# 'embedding' now contains a dense vector representation of the image\n",
        "print(\"Image Embedding Shape:\", q2.shape)\n",
        "print(\"Image Embedding:\", q2)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zuaO27NWWH5",
        "outputId": "1c6b6f51-a565-4a92-fcaa-668ba3606ebc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Embedding Shape: (512,)\n",
            "Image Embedding: [ 0.00058278 -0.01463297 -0.10330155  0.03984535  0.08525636  0.08029363\n",
            " -0.01011138  0.04867227 -0.00259888 -0.0077198  -0.0331905   0.06225294\n",
            "  0.01708761 -0.00982595 -0.01638006  0.00054205  0.04426373  0.00519726\n",
            "  0.04448376 -0.08979201 -0.06033407 -0.00162232  0.09186839  0.03262272\n",
            "  0.06873461  0.02532319  0.03512866 -0.05809444  0.00151727  0.05172818\n",
            " -0.04107905 -0.03755797 -0.04134395 -0.00761167 -0.00674731  0.04443471\n",
            "  0.00570058 -0.02845279 -0.12002273  0.05528227  0.00132485  0.00437373\n",
            " -0.02495593  0.01842853 -0.00357915  0.01889837  0.02980521  0.10357354\n",
            " -0.11238679 -0.02633037  0.02794239 -0.0152881   0.04015452 -0.0039458\n",
            " -0.09202526  0.0715652  -0.03382103  0.07384298  0.01921727 -0.04263638\n",
            "  0.02758526  0.03841295 -0.04435986 -0.05347932 -0.04511738  0.03700717\n",
            " -0.00194125 -0.00450149  0.03157888  0.02796174  0.02416223  0.01202647\n",
            " -0.00905218  0.00880154  0.0189873  -0.01363976 -0.0499587  -0.01557556\n",
            "  0.02297474  0.0651246   0.0614766   0.02845725  0.00367925  0.03151315\n",
            " -0.00906348  0.04034334  0.00219301  0.05856943 -0.00909011 -0.01423355\n",
            "  0.01797742  0.01435157  0.05880354 -0.04344825  0.10147727 -0.04386036\n",
            " -0.01284018  0.02154127 -0.06004561  0.05457702  0.04566431 -0.01077684\n",
            "  0.00699712  0.02765366  0.00357566  0.05447806 -0.01310005 -0.02255299\n",
            "  0.01432354 -0.07601233  0.04908508  0.00389152 -0.06607237 -0.08058616\n",
            "  0.0263547  -0.02808471  0.0695286  -0.00038021 -0.03878854  0.02984364\n",
            " -0.00256646  0.02118442  0.00133815 -0.0472773  -0.01195588 -0.0669666\n",
            " -0.0071366   0.04453232  0.00111025 -0.02842125 -0.0175714  -0.00643478\n",
            "  0.04876323 -0.06472842 -0.09787413  0.00334867  0.00187649 -0.00024767\n",
            "  0.06938788  0.10385709 -0.02833053 -0.00792771 -0.00623726  0.03481311\n",
            "  0.07992636 -0.05045125 -0.00808156  0.00769071  0.05459293 -0.06051681\n",
            "  0.02623133 -0.04237332 -0.01461612  0.07601271  0.02316507 -0.06920444\n",
            "  0.05341151  0.0485434   0.03503026 -0.02546098  0.07508431  0.04377884\n",
            " -0.02852262  0.02682048  0.09139965  0.04641375 -0.05197915 -0.02836282\n",
            " -0.06560951  0.04164857 -0.01279163 -0.00395267 -0.00660236  0.00338493\n",
            "  0.05723305  0.04263638  0.04826457 -0.02185955 -0.08236013  0.0287613\n",
            " -0.04757535 -0.00422647 -0.08301193  0.06606403  0.04168128  0.04225906\n",
            "  0.03009798  0.05508625  0.02304784  0.02956334  0.02328967 -0.03885793\n",
            "  0.09149846 -0.09700762  0.05365682 -0.02802743  0.06186439  0.04086529\n",
            " -0.02531239  0.06880185  0.03396954 -0.05555064  0.02037002 -0.04165684\n",
            "  0.03669901  0.0640901   0.03570412 -0.00553594  0.04140023  0.02657003\n",
            " -0.06931031 -0.03869386 -0.04545971  0.01155922 -0.00488004  0.0426462\n",
            " -0.0636877   0.03799228 -0.02469095 -0.01786827 -0.11714919 -0.0975224\n",
            " -0.01709365 -0.05293322 -0.00160847  0.03877039 -0.06770448 -0.00353634\n",
            " -0.01539879 -0.00023611 -0.009705    0.0525001  -0.01574586 -0.05584005\n",
            "  0.02420623 -0.00578888  0.01579252 -0.07729022 -0.02444515 -0.02403441\n",
            " -0.01252517 -0.0195509   0.01120158 -0.01532311  0.09776177  0.07899044\n",
            " -0.01579785  0.03239097 -0.01639406  0.05716111  0.05955906  0.07648396\n",
            "  0.01000867 -0.00473776  0.04412794 -0.02058393  0.02995613  0.03681798\n",
            "  0.0209659   0.05551313 -0.00472502 -0.01202328  0.02113431 -0.01948468\n",
            " -0.05865138 -0.02253946  0.06847092  0.00293734 -0.03504635  0.01365006\n",
            " -0.09010956 -0.00802817 -0.04642696 -0.02624361 -0.06792872 -0.05286164\n",
            "  0.02717434  0.01057739  0.01564983 -0.06623219  0.06408169  0.03001962\n",
            " -0.01631466 -0.04925485 -0.02576832 -0.04653771 -0.01977751 -0.00355507\n",
            " -0.03372259 -0.07618748  0.02066366 -0.06482755  0.03217461 -0.01092269\n",
            " -0.01718775 -0.02406414  0.00717621  0.07962366  0.03695744  0.03045471\n",
            "  0.09488815  0.00117036  0.02282127  0.01545661  0.03193149 -0.03805847\n",
            " -0.03073642 -0.06083288 -0.02635645  0.0254594  -0.02669582  0.01615116\n",
            "  0.01507757  0.01439681  0.04895734  0.02372173 -0.04542394  0.06016143\n",
            "  0.00688547 -0.00513737  0.10314457  0.01167683 -0.04161828  0.01970115\n",
            " -0.07644531  0.07899482  0.02732771  0.02116577  0.05548168  0.03341798\n",
            "  0.04803425  0.02059413 -0.00346371  0.06049509  0.00493905 -0.04375328\n",
            "  0.01996547  0.03197958  0.04180827  0.02040025  0.05875337  0.01775215\n",
            "  0.03359037 -0.00116151 -0.03342745 -0.02892528 -0.01895843  0.05830195\n",
            "  0.03731528 -0.04010315  0.01020672  0.02329778 -0.04411007 -0.08327088\n",
            " -0.05110124  0.01217918  0.09359314 -0.02469934 -0.02297806 -0.03897167\n",
            "  0.02345902  0.00067792 -0.06096138 -0.01937438 -0.02764596  0.01525408\n",
            "  0.07700519 -0.03905027  0.00822655 -0.03271889 -0.07537898 -0.01849484\n",
            "  0.01702019  0.0040585   0.0699041   0.04940457 -0.06243282 -0.00178328\n",
            " -0.01065948 -0.00928921 -0.02235799 -0.05218275 -0.06756899  0.0613427\n",
            "  0.00699825 -0.03643901 -0.02644681 -0.01890211  0.02612516 -0.03388806\n",
            "  0.00105624  0.05355155 -0.00194111 -0.02571725 -0.04154576 -0.00361628\n",
            "  0.08862311  0.03117609  0.06117413  0.02730942 -0.08572201  0.08137289\n",
            "  0.00439804 -0.00416813 -0.01750178  0.01217526  0.00269837 -0.04631697\n",
            "  0.05641455 -0.00846761  0.04905433 -0.02528094  0.00193327 -0.02050643\n",
            " -0.02846969 -0.00645685  0.05126152  0.03582475  0.0033618  -0.04733974\n",
            "  0.02973489 -0.0122521  -0.03350455  0.06956115 -0.0429418   0.00483133\n",
            "  0.02245149 -0.00588596  0.02491498 -0.06521189  0.01002998  0.04180297\n",
            " -0.0244523   0.00798181 -0.05623091 -0.04452998  0.01560469  0.00986408\n",
            " -0.02810116 -0.01782225 -0.05889104 -0.0351436  -0.00859083  0.10779268\n",
            " -0.01023237  0.06080008 -0.10309302  0.01397533  0.02526072 -0.07942653\n",
            "  0.01960654  0.05659704  0.00549258 -0.09367355  0.0263099  -0.00264487\n",
            " -0.00870358  0.09565648  0.07037158  0.00666058  0.01199247  0.04150009\n",
            " -0.03298025  0.02638438  0.06660346 -0.05924815 -0.09617335  0.01599596\n",
            "  0.03302556 -0.00165851  0.00336149 -0.00456443  0.00200567 -0.02196456\n",
            " -0.09801189 -0.00093401  0.09824389 -0.00995049  0.00316581  0.03275843\n",
            " -0.00061821  0.01058625  0.00352063 -0.02993771  0.03894569  0.05737574\n",
            " -0.10843383  0.02968427  0.05140879 -0.06388002  0.01988242 -0.04600152\n",
            " -0.03955155  0.00290028  0.07266345 -0.01782443 -0.0110463  -0.0075507\n",
            "  0.03013197  0.01059503 -0.03528689 -0.004358    0.02702685 -0.01792463\n",
            "  0.00025843  0.06066977  0.06143346  0.03103392 -0.02381746 -0.01173486\n",
            "  0.04217441 -0.06347054]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"./images/s1.jpg\"\n",
        "cat2 = create_image_embedding(image_path)\n",
        "\n",
        "# 'embedding' now contains a dense vector representation of the image\n",
        "print(\"Image Embedding Shape:\", cat2.shape)\n",
        "print(\"Image Embedding:\", cat2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Gh9cIPxPWbRA",
        "outputId": "9cf7c803-e05c-46b4-c70e-dfa1f0a5725e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Embedding Shape: (512,)\n",
            "Image Embedding: [ 7.76378484e-03  1.38627877e-02  3.42880785e-02  5.59410453e-02\n",
            "  4.43015993e-02  4.22530621e-02  3.66532840e-02  9.78047494e-03\n",
            " -1.34703349e-02  1.68228522e-02  8.26280266e-02  7.83666130e-03\n",
            "  4.87103760e-02 -3.90704256e-03  1.06615685e-02 -7.18539953e-02\n",
            " -4.96409610e-02  1.04582205e-01  1.67736411e-02  2.15226728e-02\n",
            " -2.09242180e-02  8.07328224e-02  1.67470835e-02 -1.14253521e-01\n",
            " -4.25868072e-02 -2.27696840e-02 -1.50764631e-02 -4.02070023e-02\n",
            " -2.33913157e-02 -4.37326618e-02  7.05495998e-02  7.63667449e-02\n",
            "  5.58592677e-02  1.28479674e-02  3.95264030e-02 -4.74360399e-02\n",
            "  1.70672743e-03  1.20020993e-02 -4.78693005e-03 -1.22949760e-02\n",
            "  1.39081292e-02 -2.78096441e-02  2.48735808e-02 -2.39850115e-03\n",
            " -1.18011301e-02  3.69508145e-03 -4.81235720e-02  1.29993325e-02\n",
            " -6.90511912e-02 -8.01179186e-02 -2.32403465e-02 -6.55335188e-02\n",
            "  3.54257748e-02  5.77532388e-02  1.61157586e-02 -5.35045713e-02\n",
            "  3.46317366e-02  4.95921448e-02 -6.57782704e-02 -2.87748780e-02\n",
            "  1.33648114e-02  2.92463489e-02 -7.16798892e-03 -2.60961298e-02\n",
            " -3.84725630e-02 -5.41980080e-02 -2.72227060e-02 -9.77029949e-02\n",
            " -5.60861547e-03  1.73442401e-02  1.20176934e-02  1.33096920e-02\n",
            " -6.81875497e-02 -5.93172684e-02  9.24794376e-02 -4.42040712e-02\n",
            "  1.17073935e-02  1.30964639e-02 -1.02159875e-02 -6.60966262e-02\n",
            "  2.74766097e-03  5.66387810e-02 -5.15496060e-02 -1.35784566e-01\n",
            " -1.71666276e-02  6.00463450e-02  3.63181606e-02 -1.67583432e-02\n",
            " -4.53567319e-02 -1.23792412e-02 -2.19547115e-02 -3.62854227e-02\n",
            " -1.21332277e-02 -2.44936086e-02  6.26917779e-02  2.22552717e-02\n",
            "  2.98874136e-02  2.22025588e-02 -9.66426283e-02  7.29883313e-02\n",
            " -3.75597505e-03  3.08721773e-02  5.43332100e-02 -3.68908653e-03\n",
            "  7.37921987e-03 -3.98004688e-02  9.52879805e-03  1.75728649e-02\n",
            " -4.73739766e-02  5.80539145e-02  1.49614848e-02  4.65174206e-02\n",
            " -4.73917313e-02 -9.55479369e-02 -1.30020827e-03  3.58438864e-02\n",
            "  2.92868987e-02  8.70078877e-02 -2.50851661e-02  5.11971526e-02\n",
            " -7.66126141e-02  1.13216108e-02 -1.16875386e-02  3.18520553e-02\n",
            " -7.28361383e-02  9.24174674e-03  5.45233153e-02 -9.25382376e-02\n",
            "  1.96304452e-03 -4.51774783e-02  7.02419132e-02 -4.51019742e-02\n",
            "  4.93133478e-02  9.41087212e-03  2.20235586e-02  6.03108779e-02\n",
            "  4.44470979e-02  9.01812129e-03 -8.82950891e-03 -2.89288219e-02\n",
            "  8.10177438e-03  3.38467509e-02 -4.21001464e-02  6.73301220e-02\n",
            " -2.65432876e-02  5.14418371e-02  2.14178627e-03  1.92509014e-02\n",
            " -5.67111745e-03  2.74719088e-03  3.62339877e-02 -1.61316209e-02\n",
            " -1.28224179e-01 -4.17471454e-02  9.63695645e-02 -1.34603325e-02\n",
            " -9.35380831e-02  4.97768186e-02  4.49721469e-03  3.34447138e-02\n",
            " -7.44952187e-02  4.41344939e-02  2.08500982e-03  7.14628175e-02\n",
            " -6.58861399e-02  1.71503481e-02 -7.69790933e-02 -2.24910048e-03\n",
            "  3.71600734e-03  7.36787766e-02 -3.01399883e-02  5.64339512e-04\n",
            "  2.36860197e-02  6.51071826e-03 -1.52252289e-02  2.28912495e-02\n",
            " -3.94456349e-02  1.33162243e-02 -4.88440581e-02  2.79314108e-02\n",
            "  6.11856161e-03  1.17555913e-02  5.45368344e-02  2.21735612e-02\n",
            "  1.01567462e-01  1.83181686e-03  1.36150345e-01 -5.65424736e-04\n",
            "  9.66723040e-02  5.26050758e-03  2.86572445e-02  3.75467837e-02\n",
            "  5.86601458e-02  1.19750528e-02  1.85744930e-02 -4.47005453e-03\n",
            " -5.86419478e-02 -5.42708114e-02  5.27157523e-02 -7.78222308e-02\n",
            "  1.14250705e-01 -4.96455505e-02  5.06820008e-02 -1.78408735e-02\n",
            " -2.06031911e-02  3.14575844e-02 -4.43294458e-02  5.66000957e-03\n",
            "  1.68448128e-02 -9.91806737e-04 -3.69748957e-02 -7.28525221e-02\n",
            " -3.49484431e-03 -1.70017760e-02 -1.93793736e-02 -7.71907740e-04\n",
            "  1.01750888e-01 -4.65802774e-02  1.33326929e-02  1.83004048e-02\n",
            "  1.40869832e-02  3.63097824e-02  1.27118351e-02  5.97142391e-02\n",
            "  2.85159722e-02 -1.92761663e-02  7.04711452e-02 -3.32086068e-03\n",
            " -3.56172509e-02 -4.41055465e-03 -1.44732622e-02  1.00005746e-01\n",
            "  6.86178962e-03 -9.96520557e-03 -6.38688728e-02  7.65028223e-02\n",
            " -3.80020551e-02  3.91958207e-02  6.80253506e-02  2.49275248e-02\n",
            " -1.09814711e-01  3.56751238e-03 -3.75152640e-02  3.69580872e-02\n",
            "  1.40137470e-03 -5.07759154e-02  3.74523364e-02 -1.19550623e-01\n",
            "  7.02822534e-03  8.97310227e-02 -2.02415777e-05 -2.71951500e-02\n",
            "  2.10960004e-02 -1.76199130e-03  1.69102196e-02  3.16304266e-02\n",
            " -3.24133970e-02  2.45009605e-02 -4.55224101e-04  1.52270729e-02\n",
            " -1.44037670e-02  5.11877537e-02  4.06553224e-02  2.30162498e-02\n",
            " -5.74520864e-02 -3.59858014e-02  7.97812734e-03  2.39289701e-02\n",
            "  7.78867304e-03 -7.12133721e-02  5.17319441e-02  3.54757085e-02\n",
            " -2.98206368e-03 -1.24428635e-02  4.75401804e-02  1.11679453e-02\n",
            "  1.35332961e-02 -5.93988150e-02  3.60224955e-02  5.34510911e-02\n",
            "  1.73241198e-02  7.53577650e-02 -7.69886225e-02 -6.47578835e-02\n",
            " -2.17682458e-02  1.27790282e-02  3.61313000e-02 -3.68935838e-02\n",
            " -3.71016078e-02  1.04671763e-02  6.07686164e-03 -2.37216298e-02\n",
            "  2.95480099e-02  6.64251745e-02  1.48287043e-02 -1.85798500e-02\n",
            "  5.46345487e-03 -4.70231473e-02 -5.05926041e-03 -4.09380049e-02\n",
            " -2.61370256e-03  6.40212819e-02 -7.19646196e-05  3.19367871e-02\n",
            "  9.31114051e-03 -1.94759015e-03 -4.32936810e-02  4.60799001e-02\n",
            " -5.94974086e-02  1.96509212e-02 -3.83692491e-03  7.20343590e-02\n",
            "  8.95578563e-02  9.14972052e-02  4.88447510e-02  4.07453291e-02\n",
            "  5.18323742e-02 -6.00317642e-02 -3.85120697e-03 -3.94102000e-02\n",
            "  2.93666720e-02 -2.28005536e-02 -4.38708514e-02  2.86182947e-02\n",
            "  3.75901684e-02 -2.13397779e-02  2.47422419e-02  4.66584554e-03\n",
            "  1.44161619e-02 -2.49854252e-02 -4.55838777e-02  5.42040542e-02\n",
            "  1.25792669e-02 -5.46378456e-03 -3.62196751e-02  9.18032750e-02\n",
            "  4.82125096e-02 -2.46436764e-02 -3.90063860e-02 -4.79358397e-02\n",
            "  6.18138511e-05 -3.24951150e-02 -8.44965514e-04  2.72285622e-02\n",
            "  5.77807566e-03  1.25256199e-02 -6.47303695e-03  2.37730108e-02\n",
            " -4.76353355e-02 -1.97492447e-02 -4.73502092e-02  6.55321255e-02\n",
            " -1.84846995e-03  7.02921748e-02  3.46888378e-02  5.13258129e-02\n",
            "  7.81116113e-02  1.44243920e-02  4.64792065e-02  1.62513610e-02\n",
            "  1.40128576e-03  4.87961015e-03 -2.28351960e-03  1.01209451e-02\n",
            " -3.46758030e-02  5.79160340e-02 -9.75552797e-02  6.13142364e-02\n",
            " -5.32289548e-03  2.40072589e-02  6.09650416e-03 -6.24088459e-02\n",
            " -4.34917808e-02  1.39547838e-02 -4.28758450e-02  2.18541268e-02\n",
            "  2.69848295e-02  2.43097786e-02  5.46002667e-03 -3.01392749e-02\n",
            "  1.23984069e-02 -1.23263234e-02  4.88525294e-02 -4.69718613e-02\n",
            "  3.06189619e-02 -4.80947159e-02 -6.17315806e-03 -5.55271730e-02\n",
            " -2.11060932e-03  1.95178073e-02  1.79617424e-02 -1.64129697e-02\n",
            "  7.35288719e-03  1.64800938e-02  1.68889705e-02  1.27309887e-02\n",
            " -2.23991200e-02  8.54902342e-02  1.79819134e-03  3.19757760e-02\n",
            " -5.01264855e-02 -8.58974550e-03  3.10516283e-02  1.94656197e-02\n",
            "  5.20680733e-02  2.90778223e-02 -7.18047097e-02 -7.72344321e-03\n",
            "  5.82657307e-02 -2.00119913e-02  3.30253653e-02  2.28906353e-03\n",
            " -6.85123261e-03 -5.98944239e-02 -2.11149976e-02  4.52211034e-03\n",
            " -1.92536805e-02 -3.62476008e-03  3.82426009e-02 -5.42051196e-02\n",
            "  1.66287832e-02 -5.00509255e-02 -2.07497608e-02  3.68329175e-02\n",
            " -2.63065994e-02  1.16164694e-02  2.00468097e-02 -3.40788998e-02\n",
            " -1.52380075e-02 -7.04959687e-03 -6.64521903e-02  6.00460730e-02\n",
            " -2.28707977e-02 -6.05974272e-02  4.49177511e-02  3.11775170e-02\n",
            " -7.16427565e-02 -9.11885127e-02 -3.43095958e-02 -6.53048307e-02\n",
            " -7.32368929e-03  4.93340846e-03 -2.79968977e-03  1.77632188e-04\n",
            "  2.22169012e-02 -1.25159338e-01 -8.77434574e-03  7.70308357e-03\n",
            " -8.37685689e-02 -2.38030218e-03 -1.38819199e-02 -3.58492509e-02\n",
            " -6.59921542e-02 -8.87616351e-03 -2.50451770e-02 -1.38345864e-02\n",
            " -1.50988065e-02  2.61421595e-02  2.14549247e-02  2.74033174e-02\n",
            " -2.24486757e-02  1.36897042e-01  5.97219281e-02  3.43995504e-02\n",
            " -3.68034616e-02  9.90555137e-02  5.72617259e-03  7.98852742e-03\n",
            "  3.17643918e-02 -1.15444011e-03  2.22948026e-02 -8.19727480e-02\n",
            " -2.44736336e-02 -3.77135910e-02 -3.72394361e-02 -4.48852703e-02\n",
            " -3.46836746e-02  5.57406470e-02  2.22214051e-02  1.33443996e-02\n",
            " -2.07721926e-02 -3.50483842e-02  1.16265006e-02  6.43413141e-03\n",
            "  1.25987381e-02 -3.73558849e-02  3.82581800e-02 -6.39281760e-04\n",
            " -1.17770452e-02 -2.46396195e-02 -3.05028148e-02 -2.71748044e-02\n",
            " -1.51610048e-02 -4.10503522e-02  1.32630265e-03 -4.55399565e-02\n",
            "  3.61582115e-02  2.38949270e-03  1.35977357e-03  2.27696281e-02\n",
            "  1.31506175e-02 -5.87612949e-02  5.31763174e-02 -4.84416224e-02\n",
            " -7.12555051e-02  2.23901179e-02  4.09953110e-02 -3.39812636e-02\n",
            "  2.66649295e-02 -6.09346107e-02 -1.21593170e-01  2.65079048e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = create_image_embedding(\"./images/q1.jpg\")\n",
        "q2 = create_image_embedding(\"./images/q2.jpg\")\n",
        "q3 = create_image_embedding(\"./images/q3.jpg\")\n",
        "q4 = create_image_embedding(\"./images/q4.jpg\")\n",
        "s1 = create_image_embedding(\"./images/s1.jpg\")\n",
        "z1 = create_image_embedding(\"./images/z1.jpg\")\n",
        "z2 = create_image_embedding(\"./images/z2.jpg\")"
      ],
      "metadata": {
        "id": "J_vWhX8WWxrZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U milvus-lite #yeh ek aur vector database hai, bss aesi kerlia hum kisi ki bhi kerlety hain\n",
        "\n",
        "!pip install -U pymilvus\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "GBFSG6rUW_hE",
        "outputId": "b308fd1d-e0c7-4c18-fa35-e5fc3c891fad"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting milvus-lite\n",
            "  Downloading milvus_lite-2.4.11-py3-none-manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from milvus-lite) (4.67.1)\n",
            "Downloading milvus_lite-2.4.11-py3-none-manylinux2014_x86_64.whl (45.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: milvus-lite\n",
            "Successfully installed milvus-lite-2.4.11\n",
            "Collecting pymilvus\n",
            "  Downloading pymilvus-2.5.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (75.1.0)\n",
            "Collecting grpcio<=1.67.1,>=1.49.1 (from pymilvus)\n",
            "  Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (5.29.3)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (1.0.1)\n",
            "Collecting ujson>=2.0.0 (from pymilvus)\n",
            "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (2.2.2)\n",
            "Requirement already satisfied: milvus-lite>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus) (2.4.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from milvus-lite>=2.4.0->pymilvus) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n",
            "Downloading pymilvus-2.5.3-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ujson, grpcio, pymilvus\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.69.0\n",
            "    Uninstalling grpcio-1.69.0:\n",
            "      Successfully uninstalled grpcio-1.69.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-1.67.1 pymilvus-2.5.3 ujson-5.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "grpc"
                ]
              },
              "id": "2d1f1f800e894b8984db9bcfa4ee4284"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n"
      ],
      "metadata": {
        "id": "PgvqsKUsXPk4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "import numpy as np\n",
        "\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n",
        "client.create_collection(\n",
        "    collection_name=\"images\",\n",
        "    dimension=512  # The vectors we will use in this demo has 384 dimensions\n",
        ")"
      ],
      "metadata": {
        "id": "3NMplTkTX-y9"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    {\"id\": 1, \"person_name\": \"Qasim\", \"vector\": q1},\n",
        "    {\"id\": 2, \"person_name\": \"Qasim\", \"vector\": q2},\n",
        "    {\"id\": 3, \"person_name\": \"mike o hearn\", \"vector\": q3},\n",
        "    {\"id\": 4, \"person_name\": \"mike o hearnn\", \"vector\": q4},\n",
        "    {\"id\": 3, \"person_name\": \"Shahzad\", \"vector\": s1},\n",
        "    {\"id\": 5, \"person_name\": \"Zia Khan\", \"vector\": z1},\n",
        "    {\"id\": 6, \"person_name\": \"Zia Khan\", \"vector\": z2}\n",
        "]\n"
      ],
      "metadata": {
        "id": "K6OQdShOYBL4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.insert(\n",
        "    collection_name=\"images\",\n",
        "    data=data\n",
        ")"
      ],
      "metadata": {
        "id": "cyyFi1tzYGRG"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[s1],\n",
        "    limit=1,\n",
        "    output_fields=[\"id\", \"person_name\"],\n",
        ")\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4U1UgU4YIYD",
        "outputId": "9fe0cbf8-fee5-4236-ea1d-239be1f13385"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 3, 'distance': 1.0, 'entity': {'person_name': 'Shahzad', 'id': 3}}]\"] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q3 = create_image_embedding('./images/q3.jpg')\n",
        "q3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3zYbJl2RYbbn",
        "outputId": "e09b555d-6b15-4048-8825-c86e96e5fe2a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.28181425e-02, -9.12782028e-02, -7.24859759e-02,  4.09199074e-02,\n",
              "        2.08642762e-02, -2.11638305e-02,  7.57042244e-02,  3.71956527e-02,\n",
              "       -2.11881474e-02, -3.53625305e-02,  1.96012831e-03,  2.43316609e-02,\n",
              "        4.32874858e-02, -1.30338110e-02,  1.00757135e-02, -2.36371588e-02,\n",
              "       -3.09946965e-02,  6.42171875e-02, -4.66167070e-02, -1.96986292e-02,\n",
              "       -1.04476005e-01,  4.13554832e-02,  7.77299097e-03, -9.41457674e-02,\n",
              "       -6.16693310e-02,  7.16715958e-03, -4.28025909e-02, -6.25289902e-02,\n",
              "       -3.88814392e-03, -4.47680466e-02,  5.22536971e-03,  4.50670160e-02,\n",
              "       -3.86253884e-03, -1.56821162e-02,  8.39660689e-03,  4.03827708e-03,\n",
              "       -6.02272199e-03,  7.67118623e-03, -1.43901244e-01,  3.24890502e-02,\n",
              "       -3.49450149e-02,  5.33406101e-02,  4.45074812e-02, -6.62186369e-02,\n",
              "        2.97807506e-03, -4.90045696e-02,  7.04029202e-02,  8.13547820e-02,\n",
              "       -6.76121414e-02, -4.68713418e-02, -8.21815711e-03,  9.74218696e-02,\n",
              "        5.51769547e-02, -4.51322012e-02, -6.14509769e-02,  1.33011136e-02,\n",
              "       -4.66340445e-02,  6.25225678e-02, -5.08785173e-02,  3.40623558e-02,\n",
              "       -3.16815823e-02,  5.58753759e-02,  2.54549552e-02, -4.41651680e-02,\n",
              "       -2.51904875e-02,  1.52963365e-03, -4.00384553e-02, -6.09636400e-03,\n",
              "        1.82389468e-03, -3.56867202e-02, -2.90066097e-02,  4.12645638e-02,\n",
              "       -7.19666062e-03, -9.19344574e-02,  5.26882373e-02, -8.79338756e-02,\n",
              "        5.67748025e-02, -5.35458922e-02, -2.18459480e-02, -5.40110432e-02,\n",
              "       -7.21370652e-02,  3.41871381e-02,  1.23613998e-02, -2.68586371e-02,\n",
              "       -2.77784243e-02,  6.19608350e-03,  3.30104828e-02, -2.53878068e-03,\n",
              "       -3.94896865e-02, -6.43132348e-03,  6.88581616e-02, -2.67405435e-03,\n",
              "        6.19889423e-02, -9.59131122e-02,  5.24147414e-02,  2.79518571e-02,\n",
              "        4.28822897e-02, -5.95819727e-02, -6.03725165e-02,  1.22154700e-02,\n",
              "        2.70740502e-02, -4.55953702e-02,  5.87038696e-02,  4.76573482e-02,\n",
              "       -3.48542258e-02, -1.32085579e-02,  1.98296774e-02,  1.68640576e-02,\n",
              "        1.08907986e-02,  1.12967594e-02,  3.57461758e-02,  6.44453317e-02,\n",
              "       -2.47331839e-02, -6.63761608e-03, -4.16668393e-02, -5.92922531e-02,\n",
              "        2.49128509e-02,  1.99294686e-02, -3.56233083e-02,  4.40528765e-02,\n",
              "       -6.80334195e-02, -3.70792076e-02,  1.98446121e-02, -2.64150533e-03,\n",
              "       -7.50084817e-02, -1.04050152e-02, -3.19774449e-02, -2.45341728e-03,\n",
              "        1.88453663e-02, -3.53095196e-02,  2.87040714e-02, -6.56977966e-02,\n",
              "        1.08012758e-01, -2.13861652e-02, -4.55884300e-02,  3.62108909e-02,\n",
              "       -2.02529482e-03,  1.47397618e-03,  8.11641514e-02,  4.42278162e-02,\n",
              "        1.34083908e-02,  5.64706326e-02, -1.39766429e-02,  7.51036182e-02,\n",
              "        2.11066846e-02, -4.02598642e-03, -5.77779226e-02, -3.69295403e-02,\n",
              "        2.22781561e-02,  1.08164646e-01,  5.25559969e-02, -5.11312000e-02,\n",
              "       -6.24845140e-02,  1.96166150e-02,  5.14403135e-02, -4.89494018e-02,\n",
              "        5.23691326e-02,  2.28364263e-02,  6.18079910e-03, -1.90334907e-03,\n",
              "        1.61839146e-02, -1.57793369e-02, -4.63156849e-02,  3.90848657e-03,\n",
              "        2.99307723e-02,  4.21161987e-02, -4.68248501e-02, -2.34046802e-02,\n",
              "       -3.11110988e-02, -2.02336963e-02,  2.62720231e-03,  4.66606878e-02,\n",
              "       -8.22783168e-03, -2.64239311e-02, -9.11537278e-03, -9.96494479e-03,\n",
              "       -1.77288533e-03,  2.23691296e-03, -4.42207605e-02,  2.84245964e-02,\n",
              "       -9.41155925e-02,  3.05866189e-02,  6.91516558e-03, -2.94218934e-03,\n",
              "        1.08401831e-02,  6.74122050e-02,  1.07462844e-02, -4.35096771e-02,\n",
              "        1.74440648e-02,  2.22792365e-02,  2.81359348e-02, -4.28036042e-02,\n",
              "        1.46615142e-02,  1.40113421e-02, -1.83134265e-02,  5.76812401e-02,\n",
              "        1.12098577e-02,  5.66810705e-02, -3.69775034e-02, -2.99361795e-02,\n",
              "        1.15488926e-02, -7.70433480e-03, -7.34219328e-02, -9.16471034e-02,\n",
              "       -1.45212123e-02, -4.61777709e-02, -2.04247087e-02, -1.75199192e-02,\n",
              "       -5.15993685e-02,  1.67152882e-02, -1.44623341e-02, -6.41388670e-02,\n",
              "        5.13745397e-02, -8.89722910e-03, -1.86137594e-02,  5.98507486e-02,\n",
              "       -2.80204602e-02,  2.49548461e-02, -4.48579108e-03,  2.56439261e-02,\n",
              "        1.94440335e-02, -6.61264285e-02, -5.23092784e-02, -3.12228519e-02,\n",
              "        2.56301332e-02,  3.56533891e-03,  3.00267637e-02, -4.30742130e-02,\n",
              "       -2.80849561e-02,  2.65847351e-02,  6.61116838e-02,  8.63695517e-02,\n",
              "       -2.03618929e-02, -9.02494565e-02, -2.42892317e-02,  2.88437475e-02,\n",
              "       -1.58480238e-02,  9.75005701e-03,  7.28974640e-02, -1.04101092e-01,\n",
              "       -1.25516504e-02, -1.17604733e-01, -1.65020600e-02, -4.21813875e-02,\n",
              "        6.72954321e-03, -5.26421145e-03,  6.98864534e-02,  4.86354865e-02,\n",
              "       -1.66319571e-02,  5.51395044e-02, -9.80932917e-03, -5.99825522e-03,\n",
              "        4.90455236e-03,  2.86276434e-02, -7.12369976e-04,  3.57197076e-02,\n",
              "       -2.27745231e-02, -4.92769368e-02,  4.07515988e-02,  1.08000664e-02,\n",
              "        2.38644965e-02,  2.44741272e-02,  3.31620760e-02,  1.50418347e-02,\n",
              "        1.63656138e-02, -2.62889080e-02, -9.62894112e-02,  1.17303487e-02,\n",
              "        1.50251854e-02, -1.74421147e-02, -2.28015315e-02,  2.00913623e-02,\n",
              "       -3.44984396e-03, -2.48662625e-02,  4.31990176e-02, -1.02735192e-01,\n",
              "       -1.22783352e-02, -2.65056379e-02, -5.35267480e-02,  8.88645276e-02,\n",
              "        3.32226194e-02, -1.94773264e-02, -2.97544505e-02, -7.83802494e-02,\n",
              "       -1.12417698e-01, -4.12288569e-02, -2.20100284e-02,  1.77714825e-02,\n",
              "       -3.44537087e-02, -2.07140315e-02, -8.29731929e-04, -3.80650461e-02,\n",
              "        2.73380931e-02,  1.16462848e-04,  2.90255751e-02,  1.50188338e-03,\n",
              "       -1.41633246e-02, -5.89781553e-02,  1.40854595e-02,  2.15214584e-02,\n",
              "        2.41220761e-02,  3.02278884e-02,  1.22852646e-01, -2.80359723e-02,\n",
              "        6.19396158e-02, -1.16892848e-02, -2.79108603e-02, -8.33122525e-03,\n",
              "       -4.85208211e-03,  5.92993237e-02, -9.58895497e-03,  9.98284891e-02,\n",
              "       -2.60093734e-02, -4.40126099e-03,  8.76841098e-02,  5.67437783e-02,\n",
              "       -6.00889139e-03,  2.14951169e-02, -3.87345850e-02, -6.14551306e-02,\n",
              "        5.21112904e-02, -2.70433724e-02,  1.66920554e-02,  5.70891500e-02,\n",
              "        8.48242827e-03, -9.43671167e-03, -6.28969669e-02,  3.65069509e-02,\n",
              "        1.48805380e-02,  4.17776816e-02, -2.83495579e-02,  9.84295383e-02,\n",
              "        4.09314409e-02,  4.48833406e-02, -4.63031121e-02,  1.30889975e-02,\n",
              "        3.52969840e-02,  4.29937392e-02, -2.65579652e-02,  1.00701051e-02,\n",
              "        1.73077509e-02, -1.18562463e-03, -6.38933713e-03, -2.29640212e-02,\n",
              "        3.46462354e-02,  2.04120390e-03,  2.52907332e-02,  3.60499471e-02,\n",
              "        7.00121820e-02, -6.50482774e-02, -4.75547761e-02, -3.60293826e-03,\n",
              "        8.03411379e-02, -3.61025669e-02,  2.34929807e-02, -2.02098079e-02,\n",
              "        3.80528979e-02, -1.79275554e-02,  7.08885118e-02,  2.67722290e-02,\n",
              "       -3.58803123e-02,  4.21120897e-02, -7.69320503e-02, -4.30803485e-02,\n",
              "       -6.38333559e-02,  5.94756082e-02, -7.11531332e-03, -1.40131754e-03,\n",
              "        1.93779711e-02, -5.63336238e-02, -1.67844053e-02,  1.64135266e-02,\n",
              "       -1.12461420e-02,  8.24151039e-02, -8.30690414e-02,  5.54394722e-02,\n",
              "        1.05041694e-02,  6.89872503e-02, -7.23904278e-03, -3.35865617e-02,\n",
              "       -9.17469114e-02,  7.81767350e-03, -1.16649205e-02, -4.67008501e-02,\n",
              "        4.64914180e-02,  3.81517112e-02,  1.86282098e-02, -1.01197593e-01,\n",
              "        8.05149972e-03, -4.85950224e-02, -1.49561395e-03,  4.32844684e-02,\n",
              "        1.42465159e-02, -8.40735901e-03,  4.30599153e-02,  2.80450843e-02,\n",
              "        1.55526092e-02,  7.55683407e-02,  2.84283198e-02,  1.81350149e-02,\n",
              "       -1.79424882e-02, -1.53641007e-03, -8.05460513e-02,  7.97549188e-02,\n",
              "       -5.24071679e-02, -7.93674379e-04, -3.68944667e-02, -4.17206809e-02,\n",
              "       -3.76425013e-02, -2.66655367e-02, -7.09163956e-03,  2.41567548e-02,\n",
              "        3.02765947e-02, -3.88375595e-02, -2.03376431e-02,  2.28660461e-02,\n",
              "       -3.11418662e-05,  8.10019020e-03, -1.85135659e-02, -2.87586823e-02,\n",
              "        3.97268534e-02,  2.62159985e-02, -2.69839615e-02,  5.85537888e-02,\n",
              "        4.49186750e-02, -2.10286248e-02,  5.74021339e-02,  7.03867599e-02,\n",
              "       -1.65244155e-02,  2.81522851e-02, -9.63827446e-02, -1.66557170e-02,\n",
              "       -1.69232860e-02, -6.19367510e-02, -6.14283718e-02,  1.05420966e-02,\n",
              "        5.52800577e-03,  3.83920372e-02, -4.54115309e-02, -2.35360488e-02,\n",
              "       -3.98668274e-02,  1.76744757e-03,  5.47595397e-02,  7.56414933e-03,\n",
              "        6.89827204e-02, -8.70909691e-02,  2.17138138e-02, -5.77102555e-03,\n",
              "       -4.46308590e-02, -1.57898851e-02, -2.53594648e-02,  4.55442965e-02,\n",
              "        4.78492267e-02, -6.48045316e-02,  3.80946435e-02, -4.89026494e-02,\n",
              "        2.03518267e-03,  2.00024527e-02,  4.47579809e-02, -1.42481141e-02,\n",
              "        8.30361154e-03,  9.08531100e-02,  2.60897186e-02, -3.64852734e-02,\n",
              "        3.05154063e-02,  3.29048447e-02,  8.40640292e-02, -7.78190233e-03,\n",
              "        2.44670338e-03, -8.58971104e-03, -8.22375622e-03,  2.90975254e-02,\n",
              "       -2.17106268e-02,  3.49625722e-02, -5.21663427e-02, -7.70226907e-05,\n",
              "       -2.50243377e-02, -2.56661456e-02,  8.80675241e-02,  1.42336953e-02,\n",
              "       -5.72156869e-02, -7.16928253e-03,  6.23286031e-02,  9.77747608e-03,\n",
              "        5.21386378e-02,  3.78049053e-02, -6.86071888e-02, -4.90948632e-02,\n",
              "       -5.19085638e-02, -1.53522938e-02, -1.32678142e-02,  3.83723862e-02,\n",
              "       -2.40953118e-02, -4.00623120e-02,  1.28122851e-01, -6.14145920e-02,\n",
              "        1.54712861e-02,  3.77860963e-02,  4.90093678e-02,  2.10315417e-02,\n",
              "       -7.89437667e-02, -5.08984067e-02, -4.97858077e-02, -2.94979126e-03,\n",
              "       -4.76393513e-02,  3.73048000e-02,  7.27780629e-03, -6.56230003e-03,\n",
              "        5.65653890e-02, -7.92044587e-03, -7.07582012e-02, -1.86837763e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q4 = create_image_embedding('./images/q4.jpg')\n",
        "q4\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_Z7LAECZn6_",
        "outputId": "f834858c-e97a-4174-9a4c-623b780e3ab5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-5.55733442e-02, -5.72444405e-03, -3.21428590e-02,  4.54901569e-02,\n",
              "        3.80656123e-02,  1.21296257e-01, -3.05971242e-02,  5.16034067e-02,\n",
              "       -2.11088154e-02, -6.48726821e-02, -4.02750261e-02,  9.17612091e-02,\n",
              "        7.36646308e-03,  2.49168882e-03, -9.27665364e-03,  4.66583073e-02,\n",
              "        5.92025146e-02,  1.55120646e-03,  1.67714115e-02, -1.27209678e-01,\n",
              "       -1.33256074e-02, -3.95093905e-03,  8.49130824e-02,  6.12336770e-02,\n",
              "        9.20173079e-02, -1.19456602e-02,  3.13019566e-02,  1.30276186e-02,\n",
              "       -2.27600187e-02,  4.65738922e-02, -3.14080566e-02, -4.75728661e-02,\n",
              "       -2.32998356e-02, -2.51588598e-02,  1.55847045e-02,  9.42744166e-02,\n",
              "        2.33697779e-02, -4.08550613e-02, -1.01212010e-01,  3.32756937e-02,\n",
              "        4.82657552e-02,  1.94978677e-02,  4.99893725e-02, -6.54827058e-02,\n",
              "        1.05131036e-02,  1.51001317e-02,  4.16937098e-02,  4.33719754e-02,\n",
              "       -5.39007820e-02, -6.25770027e-03,  4.43269834e-02,  5.87067902e-02,\n",
              "        5.49229756e-02, -3.51949707e-02, -2.48591118e-02,  6.16612136e-02,\n",
              "       -1.69877224e-02,  8.25794041e-02,  7.01993927e-02, -6.85772905e-03,\n",
              "        1.17293680e-02,  4.32179356e-03, -6.95207668e-03, -2.35759038e-02,\n",
              "       -4.32581119e-02,  1.09766506e-01, -2.21099202e-02,  1.19900582e-02,\n",
              "        5.41529208e-02,  1.04431761e-03, -2.23547164e-02, -4.61648544e-03,\n",
              "        3.54379751e-02,  1.89958774e-02,  5.68715595e-02,  2.28542462e-02,\n",
              "       -3.66624780e-02, -6.04309188e-03, -6.50403555e-03,  5.97925782e-02,\n",
              "        2.96857711e-02, -4.59463634e-02,  6.80597452e-03, -9.48481821e-03,\n",
              "        2.84588970e-02,  1.47379702e-02, -6.82232715e-03,  6.25081509e-02,\n",
              "       -8.64819251e-03, -3.71700269e-03, -1.28456550e-02,  4.58050184e-02,\n",
              "        6.63156435e-02, -4.23275903e-02,  2.77463626e-02, -4.25569564e-02,\n",
              "       -2.34269612e-02, -1.57664865e-02,  3.39663140e-02,  6.28585741e-02,\n",
              "        4.77484241e-02, -2.10435353e-02,  5.16924541e-04, -4.29257425e-03,\n",
              "        3.82059254e-02,  5.62389158e-02,  3.02117289e-04, -7.14146867e-02,\n",
              "        3.29237171e-02, -6.40965924e-02, -1.85437570e-03,  5.07941544e-02,\n",
              "       -4.08529490e-02, -4.81767394e-02,  2.15476621e-02, -4.21615876e-02,\n",
              "        1.50021641e-02, -4.18054871e-02, -5.95051795e-02, -1.61717292e-02,\n",
              "       -3.86414677e-02,  3.24038342e-02, -1.07976049e-02, -4.00841646e-02,\n",
              "        5.60231283e-02, -4.86421734e-02,  2.04042252e-02,  7.50669688e-02,\n",
              "        2.49676090e-02, -3.73243988e-02, -4.35109204e-03, -5.91800708e-05,\n",
              "        7.24781603e-02, -6.29233494e-02, -6.99084476e-02,  5.50171360e-02,\n",
              "        1.00918235e-02,  1.94822568e-02,  5.65201379e-02,  2.86736488e-02,\n",
              "        2.68410724e-02, -3.56495865e-02,  3.48914973e-02,  3.15278769e-02,\n",
              "        3.94382738e-02, -7.99419358e-02, -5.52964248e-02,  1.88515149e-02,\n",
              "        7.05963671e-02,  8.25314783e-03,  1.30629623e-02, -7.58002698e-02,\n",
              "       -9.21524502e-03,  6.11795634e-02,  2.37603951e-02, -3.83303948e-02,\n",
              "        7.71314278e-02,  3.24454159e-02,  7.75746768e-03,  6.43766311e-04,\n",
              "        7.09934160e-02,  2.13216972e-02, -1.23760570e-02,  5.02859391e-02,\n",
              "        9.51044187e-02,  4.63223346e-02, -4.78739701e-02, -4.83514518e-02,\n",
              "       -5.36568798e-02, -6.80051628e-04, -3.16044539e-02,  3.47405463e-03,\n",
              "        8.67744791e-04, -2.12272517e-02,  2.79489066e-02, -2.28935126e-02,\n",
              "        6.66583478e-02, -4.24492955e-02, -1.14621997e-01,  3.32255810e-02,\n",
              "       -9.64534581e-02, -1.88747309e-02, -3.50670777e-02,  3.09482049e-02,\n",
              "       -5.09285405e-02, -2.46708421e-03, -9.79428552e-03,  4.28897217e-02,\n",
              "        1.50079234e-03,  3.84575352e-02,  4.63028159e-03,  4.19917330e-02,\n",
              "        7.64183328e-02, -9.01322961e-02, -6.42815512e-03,  8.45156051e-03,\n",
              "        1.13417163e-01,  2.03302503e-02, -3.44493873e-02, -1.33299822e-04,\n",
              "       -1.25784473e-02, -8.86544585e-03,  4.79731485e-02, -6.05590455e-02,\n",
              "        3.88276353e-02,  1.06241116e-02, -4.97868583e-02, -1.55506039e-03,\n",
              "       -3.46779972e-02,  1.40187377e-02, -2.92992927e-02,  2.21307520e-02,\n",
              "        3.03426720e-02,  6.58348715e-03, -1.64339356e-02,  3.85058112e-02,\n",
              "       -5.47829308e-02, -7.62227876e-03, -5.01892008e-02, -4.23741788e-02,\n",
              "       -9.50529426e-02, -6.62369207e-02, -1.12684863e-03, -6.41364530e-02,\n",
              "        2.21799798e-02,  3.77123021e-02, -7.46161938e-02, -3.18251774e-02,\n",
              "        1.52880680e-02,  1.39858946e-02,  4.30387184e-02,  6.14411235e-02,\n",
              "       -4.90735546e-02, -1.93826910e-02,  8.27887431e-02, -2.33321618e-02,\n",
              "        6.78457320e-02, -6.52235523e-02, -4.46316712e-02, -1.93607304e-02,\n",
              "       -3.31468694e-02,  2.33249390e-03,  5.86507246e-02,  1.00056259e-02,\n",
              "        7.04673603e-02,  6.93092421e-02, -4.45690472e-03,  3.99692841e-02,\n",
              "       -3.31836343e-02, -1.13353673e-02,  3.16233002e-02,  4.11703512e-02,\n",
              "       -4.74195648e-03,  5.51576633e-03,  8.67433697e-02, -3.98694985e-02,\n",
              "       -1.38157960e-02, -3.37744318e-03,  3.32000181e-02,  7.29853138e-02,\n",
              "        2.32603811e-02, -2.00401284e-02,  4.80793491e-02,  5.12555800e-03,\n",
              "       -6.02303334e-02, -4.30407822e-02, -1.52542265e-02,  1.37786120e-02,\n",
              "       -2.80657075e-02,  3.41430865e-02, -9.91808027e-02,  2.02672407e-02,\n",
              "       -4.85006161e-02, -3.60991918e-02, -2.44578943e-02, -1.04602501e-01,\n",
              "       -1.37768872e-02, -1.08594168e-02,  1.10031175e-03, -3.20420600e-02,\n",
              "        4.24126945e-02, -2.60909125e-02, -2.93861609e-02, -6.78350851e-02,\n",
              "       -3.28552648e-02, -4.14146334e-02, -1.94508061e-02, -2.05457695e-02,\n",
              "       -3.38360332e-02, -6.72599971e-02,  5.16209677e-02,  5.09431632e-03,\n",
              "        3.68057750e-02, -3.81631181e-02,  2.06148047e-02,  4.62358110e-02,\n",
              "        5.64221060e-03,  5.58252484e-02,  2.57009398e-02,  5.39122522e-02,\n",
              "        1.21367827e-01,  1.68756191e-02,  7.10706264e-02,  9.39543359e-03,\n",
              "        6.29320890e-02, -2.54899878e-02, -4.42726677e-03, -5.00718690e-02,\n",
              "        1.14882058e-02, -5.14001474e-02, -2.29339693e-02, -4.46345983e-03,\n",
              "       -2.38793027e-02, -2.21419837e-02,  7.07092136e-02,  5.03585190e-02,\n",
              "       -2.55013630e-02,  4.74545620e-02, -3.99544314e-02, -1.38387708e-02,\n",
              "        1.03682317e-01, -3.45016792e-02, -6.98601976e-02,  3.13112303e-03,\n",
              "       -5.23704439e-02,  9.52110291e-02,  1.86600108e-02, -8.59137718e-03,\n",
              "        5.27951457e-02,  8.00013170e-02,  1.74610708e-02,  7.68392673e-03,\n",
              "       -1.37688173e-02,  9.93747730e-03, -8.04812647e-03, -4.40342398e-03,\n",
              "        2.93980800e-02,  7.96454996e-02,  1.98700521e-02,  3.13053317e-02,\n",
              "        2.13997271e-02, -4.18376774e-02,  2.41556857e-02,  2.95559429e-02,\n",
              "       -2.58446615e-02, -2.01943163e-02,  6.18641339e-02,  7.13605434e-02,\n",
              "        3.10419444e-02, -4.93113883e-02,  9.13321320e-03, -1.49510684e-03,\n",
              "        5.94102778e-03, -6.55071959e-02, -2.43132953e-02,  3.03651486e-02,\n",
              "        6.47254363e-02, -1.42625486e-02, -7.20515028e-02, -1.83010567e-02,\n",
              "        2.84887366e-02,  2.19952650e-02, -8.03786591e-02, -5.80401830e-02,\n",
              "       -2.13040551e-03,  4.93219309e-02,  2.80523729e-02, -2.92227045e-02,\n",
              "       -4.59723808e-02,  5.88856731e-03, -4.69006933e-02,  8.66434444e-03,\n",
              "        3.24684605e-02,  4.02921587e-02,  6.02996014e-02,  5.04126735e-02,\n",
              "       -3.79333161e-02, -5.77897057e-02, -1.18338214e-02,  4.66516502e-02,\n",
              "       -8.98229554e-02,  2.46618744e-02, -2.46327966e-02,  2.61295326e-02,\n",
              "        3.94737497e-02, -2.00901665e-02,  2.26389971e-02, -6.33174181e-02,\n",
              "        1.66242719e-02, -2.41780747e-02, -1.04770474e-02,  7.50514939e-02,\n",
              "        2.44921446e-02, -1.24409553e-02, -2.59707961e-02,  4.77453927e-03,\n",
              "        9.19798538e-02,  3.14993113e-02,  2.13063881e-02,  7.45568126e-02,\n",
              "       -5.50791211e-02,  2.83991490e-02, -9.20581352e-03, -4.15883921e-02,\n",
              "       -7.76378810e-02, -5.25740301e-03,  5.39807826e-02, -8.15897528e-03,\n",
              "        6.17111437e-02,  3.38332839e-02,  2.14536767e-02, -5.95556349e-02,\n",
              "        2.35804226e-02,  1.33214183e-02, -7.71121755e-02, -7.66472472e-03,\n",
              "       -3.51602398e-03,  2.93221185e-03,  1.80161875e-02, -1.73807498e-02,\n",
              "        3.92110869e-02, -1.81443766e-02, -3.00048608e-02,  1.33265499e-02,\n",
              "       -1.57439522e-02, -3.08544207e-02,  2.03696713e-02,  1.68687999e-02,\n",
              "        7.39324316e-02, -6.47250563e-02, -3.57445478e-02,  5.66815063e-02,\n",
              "        4.11698744e-02,  2.19278759e-03, -2.71041580e-02, -6.53852895e-02,\n",
              "        5.08108735e-02,  4.09312174e-02, -3.62804607e-02, -7.02662021e-02,\n",
              "       -1.74952578e-02, -1.77850779e-02,  5.80257364e-02,  5.31349517e-02,\n",
              "        3.42598632e-02,  5.03176674e-02, -6.47805780e-02,  2.99634412e-02,\n",
              "        3.17866504e-02, -3.55845392e-02,  3.57048493e-03, -1.63694695e-02,\n",
              "        6.84322417e-02, -1.04650445e-01, -2.74216989e-03, -2.81276158e-03,\n",
              "        4.74407487e-02,  7.13358447e-02,  4.64957282e-02,  1.38686402e-02,\n",
              "       -5.11961952e-02,  3.22767943e-02, -1.90704502e-02, -9.31749120e-03,\n",
              "        6.87456727e-02, -7.71943405e-02, -8.43973458e-02, -7.52819236e-03,\n",
              "        6.06205966e-03, -3.69632081e-03, -5.43963611e-02,  1.20827705e-02,\n",
              "       -2.29423065e-02,  6.51443284e-03, -7.90682659e-02, -1.59407489e-03,\n",
              "        5.23534156e-02, -7.44742481e-03,  1.37545550e-02,  1.83303934e-02,\n",
              "       -1.08523816e-02, -2.72124130e-02,  9.69359744e-03, -3.83274741e-02,\n",
              "        5.04449718e-02,  6.79452196e-02, -4.43666726e-02, -7.34994840e-03,\n",
              "        1.95596106e-02, -2.35355217e-02,  3.91350547e-03, -2.22097663e-03,\n",
              "       -1.63799152e-02,  4.23244350e-02,  9.35437456e-02,  1.85787603e-02,\n",
              "        2.09584609e-02,  5.80413081e-03,  3.24663073e-02,  5.52341379e-02,\n",
              "       -4.78876941e-02,  2.03724559e-02,  1.12968329e-02, -2.03428117e-05,\n",
              "       -3.04015558e-02,  2.50681415e-02,  1.08721562e-01,  2.26617493e-02,\n",
              "        2.78702695e-02,  5.80426641e-02, -1.73943955e-03, -5.04495651e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[z1],\n",
        "    limit=2,\n",
        "    output_fields=[\"id\", \"person_name\"],\n",
        ")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubycXA97ZFpG",
        "outputId": "4d17fa36-2229-4b06-94c3-6fd657efba7b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 5, 'distance': 0.9999998211860657, 'entity': {'person_name': 'Zia Khan', 'id': 5}}]\"] \n"
          ]
        }
      ]
    }
  ]
}